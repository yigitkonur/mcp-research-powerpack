{
  "content": [
    {
      "type": "text",
      "text": "# Scraped Content (3 URLs)\n\n**Token Allocation:** 10,666 tokens/URL (3 URLs, 32,000 total budget)\n**Status:** ‚úÖ 3 successful | ‚ùå 0 failed | üì¶ 1 batch(es)\n\n---\n\n## https://github.com/yigitkonur/llm-ocr\n\nGitHub - yigitkonur/llm-ocr: An open-source OCR API that leverages OpenAI's powerful language models with optimized performance techniques like parallel processing and batching to deliver high-quality text extraction from complex PDF documents. Ideal for businesses seeking efficient document digitization and data extraction solutions.                                             \n\n[Skip to content](#start-of-content)   \n\n## Navigation Menu\n\nToggle navigation\n\n[](/)\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Fllm-ocr)\n\nAppearance settings\n\n  \n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n\n# Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\n Include my email address so I can be contacted\n\nCancel Submit feedback\n\n# Saved searches\n\n## Use saved searches to filter your results more quickly\n\nName  \n\nQuery \n\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\n\nCancel Create saved search\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Fllm-ocr)\n\n[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=yigitkonur%2Fllm-ocr)\n\nAppearance settings\n\nResetting focus\n\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\n\n[yigitkonur](/yigitkonur) / **[llm-ocr](/yigitkonur/llm-ocr)** Public\n\n-   [Notifications](/login?return_to=%2Fyigitkonur%2Fllm-ocr) You must be signed in to change notification settings\n-   [Fork 62](/login?return_to=%2Fyigitkonur%2Fllm-ocr)\n-   [Star 875](/login?return_to=%2Fyigitkonur%2Fllm-ocr)\n    \n\nAn open-source OCR API that leverages OpenAI's powerful language models with optimized performance techniques like parallel processing and batching to deliver high-quality text extraction from complex PDF documents. Ideal for businesses seeking efficient document digitization and data extraction solutions.\n\n### License\n\n[View license](/yigitkonur/llm-ocr/blob/main/LICENSE.md)\n\n[875 stars](/yigitkonur/llm-ocr/stargazers) [62 forks](/yigitkonur/llm-ocr/forks) [Branches](/yigitkonur/llm-ocr/branches) [Tags](/yigitkonur/llm-ocr/tags) [Activity](/yigitkonur/llm-ocr/activity)\n\n[Star](/login?return_to=%2Fyigitkonur%2Fllm-ocr)\n\n[Notifications](/login?return_to=%2Fyigitkonur%2Fllm-ocr) You must be signed in to change notification settings\n\n# yigitkonur/llm-ocr\n\n  \n\n¬†main\n\n[Branches](/yigitkonur/llm-ocr/branches)[Tags](/yigitkonur/llm-ocr/tags)\n\n[](/yigitkonur/llm-ocr/branches)[](/yigitkonur/llm-ocr/tags)\n\nGo to file\n\nCode\n\nOpen more actions menu\n\n## Folders and files\n\nName\n\nName\n\nLast commit message\n\nLast commit date\n\n## Latest commit\n\n## History\n\n[15 Commits](/yigitkonur/llm-ocr/commits/main/)\n\n[](/yigitkonur/llm-ocr/commits/main/)\n\n[swift\\_ocr](/yigitkonur/llm-ocr/tree/main/swift_ocr \"swift_ocr\")\n\n[swift\\_ocr](/yigitkonur/llm-ocr/tree/main/swift_ocr \"swift_ocr\")\n\n[.env.example](/yigitkonur/llm-ocr/blob/main/.env.example \".env.example\")\n\n[.env.example](/yigitkonur/llm-ocr/blob/main/.env.example \".env.example\")\n\n[.gitignore](/yigitkonur/llm-ocr/blob/main/.gitignore \".gitignore\")\n\n[.gitignore](/yigitkonur/llm-ocr/blob/main/.gitignore \".gitignore\")\n\n[LICENSE.md](/yigitkonur/llm-ocr/blob/main/LICENSE.md \"LICENSE.md\")\n\n[LICENSE.md](/yigitkonur/llm-ocr/blob/main/LICENSE.md \"LICENSE.md\")\n\n[README.md](/yigitkonur/llm-ocr/blob/main/README.md \"README.md\")\n\n[README.md](/yigitkonur/llm-ocr/blob/main/README.md \"README.md\")\n\n[main.py](/yigitkonur/llm-ocr/blob/main/main.py \"main.py\")\n\n[main.py](/yigitkonur/llm-ocr/blob/main/main.py \"main.py\")\n\n[pyproject.toml](/yigitkonur/llm-ocr/blob/main/pyproject.toml \"pyproject.toml\")\n\n[pyproject.toml](/yigitkonur/llm-ocr/blob/main/pyproject.toml \"pyproject.toml\")\n\n[requirements.txt](/yigitkonur/llm-ocr/blob/main/requirements.txt \"requirements.txt\")\n\n[requirements.txt](/yigitkonur/llm-ocr/blob/main/requirements.txt \"requirements.txt\")\n\nView all files\n\n## Repository files navigation\n\n# ‚ö° Swift OCR ‚ö°\n\n[](#-swift-ocr-)\n\n### Stop squinting at PDFs. Start extracting clean markdown.\n\n[](#stop-squinting-at-pdfs-start-extracting-clean-markdown)\n\n**_The LLM-powered OCR engine that turns any PDF into beautifully formatted Markdown. It reads your documents like a human, handles messy layouts, and outputs text your AI can actually understand._**\n\n[![python](https://camo.githubusercontent.com/887e84deb889f9087fc5ec45dbdbfa27734a9547584c48bda0099f6ec04d49c2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e382b2d3444383745362e7376673f7374796c653d666c61742d737175617265)](#) [![fastapi](https://camo.githubusercontent.com/08c490aafb7be47e3d2b5ef602adc5c5c100fbd014c9679e08853db2e31b983e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f466173744150492d302e3130302b2d3444383745362e7376673f7374796c653d666c61742d737175617265)](#) ¬†¬†‚Ä¢¬†¬† [![license](https://camo.githubusercontent.com/a36267201062be85c080591602f3434fd0318b82d469b78c94652b58afeeb543/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4147504c5f76332d4639413832352e7376673f7374796c653d666c61742d737175617265)](https://www.gnu.org/licenses/agpl-3.0) [![platform](https://camo.githubusercontent.com/be90eb7ad01a3a68618f2facaf2ae9ab2a0550276a4362e1a5167ad90411858e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d2d6d61634f535f7c5f4c696e75785f7c5f57696e646f77732d3245443537332e7376673f7374796c653d666c61742d737175617265)](#)\n\n[![gpt-4/5 vision](https://camo.githubusercontent.com/590245edbe11240084c3c14aabb1ce3e134d1183979403eedda82d43690249e7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09fa7a05f4750542d2d342f355f566973696f6e2d706f77657265645f62795f4f70656e41492d3245443537332e7376673f7374796c653d666f722d7468652d6261646765)](https://camo.githubusercontent.com/590245edbe11240084c3c14aabb1ce3e134d1183979403eedda82d43690249e7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09fa7a05f4750542d2d342f355f566973696f6e2d706f77657265645f62795f4f70656e41492d3245443537332e7376673f7374796c653d666f722d7468652d6261646765) [![markdown output](https://camo.githubusercontent.com/9d66074480f637ba347cd92eaf6bb09df8e2e680816297b86905dead44a3e5ab/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09f939d5f6d61726b646f776e5f6f75747075742d7461626c65732c5f686561646572732c5f6c697374732d3245443537332e7376673f7374796c653d666f722d7468652d6261646765)](https://camo.githubusercontent.com/9d66074480f637ba347cd92eaf6bb09df8e2e680816297b86905dead44a3e5ab/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09f939d5f6d61726b646f776e5f6f75747075742d7461626c65732c5f686561646572732c5f6c697374732d3245443537332e7376673f7374796c653d666f722d7468652d6261646765)\n\n### üß≠ Quick Navigation\n\n[](#-quick-navigation)\n\n[**‚ö° Get Started**](#-get-started-in-60-seconds) ‚Ä¢ [**‚ú® Key Features**](#-feature-breakdown-the-secret-sauce) ‚Ä¢ [**üéÆ Usage & Examples**](#-usage-fire-and-forget) ‚Ä¢ [**üí∞ Cost Breakdown**](#-cost-breakdown-stupidly-cheap) ‚Ä¢ [**‚öôÔ∏è Configuration**](#%EF%B8%8F-configuration) ‚Ä¢ [**üèóÔ∏è Project Structure**](#%EF%B8%8F-project-structure)\n\n* * *\n\n**Swift OCR** is the document processor your AI assistant wishes it had. Stop feeding your LLM screenshots and praying it reads them correctly. This tool acts like a professional transcriber, reading every page of your PDF, intelligently handling tables, headers, and mixed layouts, then packaging everything into perfectly structured Markdown so your AI can actually work with it.\n\n### üß†\n\n[](#)\n\n**GPT-4 Vision**  \nHuman-level reading accuracy\n\n### ‚ö°\n\n[](#-1)\n\n**Parallel Processing**  \nMulti-page PDFs in seconds\n\n### üìù\n\n[](#-2)\n\n**Clean Markdown**  \nTables, headers, lists‚Äîall formatted\n\nHow it slaps:\n\n-   **You:** `curl -X POST \"http://localhost:8000/ocr\" -F \"file=@messy_document.pdf\"`\n-   **Swift OCR:** Converts pages ‚Üí Sends to GPT-4 Vision ‚Üí Formats as Markdown\n-   **You:** Get perfectly structured text with tables, headers, and lists intact.\n-   **Result:** Your AI finally understands that 50-page contract. ‚òï\n\n* * *\n\n## üìπ Demo\n\n[](#-demo)\n\nvideo.mp4\n\n_Demo video showcasing the conversion of NASA's Apollo 17 flight documents‚Äîcomplete with unorganized, horizontally and vertically oriented pages‚Äîinto well-structured Markdown format without breaking a sweat._\n\n* * *\n\n## üí• Why This Slaps Other Methods\n\n[](#-why-this-slaps-other-methods)\n\nManually extracting text from PDFs is a vibe-killer. Swift OCR makes traditional OCR look ancient.\n\n**‚ùå The Old Way (Pain)**\n\n**‚úÖ The Swift OCR Way (Glory)**\n\n1.  Run Tesseract. Get garbled text.\n2.  Tables? What tables? Just random words now.\n3.  Manually fix formatting for 2 hours.\n4.  Feed broken context to your AI.\n5.  Get a useless answer. Cry.\n\n1.  Upload PDF to Swift OCR.\n2.  Get perfectly formatted Markdown.\n3.  Tables intact. Headers preserved.\n4.  Feed clean context to your AI.\n5.  Get genius-level answers. Go grab a coffee. ‚òï\n\nWe're not just running basic OCR. We're using **GPT-4 Vision** to actually _understand_ your documents‚Äîhandling rotated pages, complex tables, mixed layouts, and even describing images for accessibility.\n\n* * *\n\n## üí∞ Cost Breakdown: Stupidly Cheap\n\n[](#-cost-breakdown-stupidly-cheap)\n\nOur solution offers an optimal balance of affordability and accuracy that makes enterprise OCR solutions look like highway robbery.\n\nMetric\n\nValue\n\n**Avg tokens/page**\n\n~1,500 (including prompt)\n\n**GPT-4o input cost**\n\n$5 per million tokens\n\n**GPT-4o output cost**\n\n$15 per million tokens\n\n**Cost per 1,000 pages**\n\n**~$15**\n\n### üí° Want It Even Cheaper?\n\n[](#-want-it-even-cheaper)\n\nOptimization\n\nCost per 1,000 pages\n\n**GPT-4o (default)**\n\n~$15\n\n**GPT-4o mini**\n\n~$8\n\n**Batch API**\n\n~$4\n\n### üÜö Market Comparison\n\n[](#-market-comparison)\n\nSolution\n\nCost per 1,000 pages\n\nTables?\n\nMarkdown?\n\n**Swift OCR**\n\n**$15**\n\n‚úÖ Perfect\n\n‚úÖ Native\n\nCloudConvert (PDFTron)\n\n~$30\n\n‚ö†Ô∏è Basic\n\n‚ùå No\n\nAdobe Acrobat API\n\n~$50+\n\n‚úÖ Good\n\n‚ùå No\n\nTesseract (free)\n\n$0\n\n‚ùå Broken\n\n‚ùå No\n\n> **Bottom line:** Half the cost of competitors, 10x the quality. It's not just about being cheaper‚Äîit's about getting output you can actually use.\n\n* * *\n\n## üöÄ Get Started in 60 Seconds\n\n[](#-get-started-in-60-seconds)\n\n### Prerequisites\n\n[](#prerequisites)\n\n-   **Python 3.8+**\n-   **Azure OpenAI** account (with GPT-4 Vision deployment)\n\n### Installation\n\n[](#installation)\n\n# Clone the repo\ngit clone https://github.com/yigitkonur/swift-ocr-llm-powered-pdf-to-markdown.git\ncd swift-ocr-llm-powered-pdf-to-markdown\n\n# Create virtual environment (recommended)\npython3 -m venv venv\nsource venv/bin/activate  # Windows: venv\\\\Scripts\\\\activate\n\n# Install dependencies\npip install -r requirements.txt\n\n### Configure Environment\n\n[](#configure-environment)\n\nCreate a `.env` file in the root directory:\n\n# Required\nOPENAI\\_API\\_KEY\\=your\\_openai\\_api\\_key\nAZURE\\_OPENAI\\_ENDPOINT\\=https://your-resource.openai.azure.com/\nOPENAI\\_DEPLOYMENT\\_ID\\=your\\_gpt4\\_vision\\_deployment\n\n# Optional (sensible defaults)\nOPENAI\\_API\\_VERSION\\=gpt-4o\nBATCH\\_SIZE\\=1                        # Images per OCR request (1-10)\nMAX\\_CONCURRENT\\_OCR\\_REQUESTS\\=5       # Parallel OCR calls\nMAX\\_CONCURRENT\\_PDF\\_CONVERSION\\=4     # Parallel page rendering\n\n### Run It\n\n[](#run-it)\n\n# Option 1: Classic uvicorn (backward compatible)\nuvicorn main:app --reload\n\n# Option 2: Using the new package\nuvicorn swift\\_ocr.app:app --reload\n\n# Option 3: As a Python module\npython -m swift\\_ocr\n\n# Option 4: With CLI arguments\npython -m swift\\_ocr --host 0.0.0.0 --port 8080 --workers 4\n\nüéâ **API is now live at `http://127.0.0.1:8000`**\n\n> **‚ú® Pro tip:** Check out the auto-generated docs at `http://127.0.0.1:8000/docs`\n\n* * *\n\n## üéÆ Usage: Fire and Forget\n\n[](#-usage-fire-and-forget)\n\n### API Endpoint\n\n[](#api-endpoint)\n\n**POST** `/ocr`\n\nAccept a PDF file upload OR a URL to a PDF. Returns beautifully formatted Markdown.\n\n### Examples\n\n[](#examples)\n\n**Upload a PDF file:**\n\ncurl -X POST \"http://127.0.0.1:8000/ocr\" \\\\\n  -F \"file=@/path/to/your/document.pdf\"\n\n**Process a PDF from URL:**\n\ncurl -X POST \"http://127.0.0.1:8000/ocr\" \\\\\n  -H \"Content-Type: application/json\" \\\\\n  -d '{\"url\": \"https://example.com/document.pdf\"}'\n\n### Response\n\n[](#response)\n\n{\n  \"text\": \"\\# Document Title\\\\n\\\\n\\## Section 1\\\\n\\\\nExtracted text with \\*\\*formatting\\*\\* preserved...\\\\n\\\\n| Column 1 | Column 2 |\\\\n|----------|----------|\\\\n| Data     | Data     |\"\n}\n\n### Response (v2.0+)\n\n[](#response-v20)\n\nThe new response includes additional metadata:\n\n{\n  \"text\": \"\\# Document Title\\\\n\\\\n\\## Section 1\\\\n\\\\nExtracted text...\",\n  \"status\": \"success\",\n  \"pages\\_processed\": 5,\n  \"processing\\_time\\_ms\": 1234\n}\n\n### Health Check\n\n[](#health-check)\n\ncurl http://127.0.0.1:8000/health\n\n{\n  \"status\": \"healthy\",\n  \"version\": \"2.0.0\",\n  \"timestamp\": \"2024-01-01T00:00:00Z\",\n  \"openai\\_configured\": true\n}\n\n### Error Codes\n\n[](#error-codes)\n\nCode\n\nMeaning\n\n`200`\n\nSuccess‚ÄîMarkdown text returned\n\n`400`\n\nBad request (no file/URL, or both provided)\n\n`422`\n\nValidation error\n\n`429`\n\nRate limited‚Äîretry with backoff\n\n`500`\n\nProcessing error\n\n`504`\n\nTimeout downloading PDF\n\n* * *\n\n## ‚ú® Feature Breakdown: The Secret Sauce\n\n[](#-feature-breakdown-the-secret-sauce)\n\nFeature\n\nWhat It Does\n\nWhy You Care\n\n**üß† GPT-4 Vision**  \n`Human-level OCR`\n\nUses OpenAI's most capable vision model to read documents\n\nActually understands context, not just character shapes\n\n**‚ö° Parallel Processing**  \n`Multiprocessing + async`\n\nConverts PDF pages and calls OCR in parallel\n\n50-page PDF in seconds, not minutes\n\n**üìä Table Preservation**  \n`Markdown tables`\n\nDetects and formats tables as proper Markdown\n\nYour data stays structured, not flattened to gibberish\n\n**üîÑ Smart Batching**  \n`Configurable batch size`\n\nGroups pages to optimize API calls vs accuracy\n\nBalance speed and cost for your use case\n\n**üõ°Ô∏è Retry with Backoff**  \n`Exponential backoff`\n\nAutomatically retries on rate limits and timeouts\n\nHandles API hiccups without crashing\n\n**üìÑ Flexible Input**  \n`File upload or URL`\n\nAccept PDFs directly or fetch from any URL\n\nWorks with your existing workflow\n\n**üñºÔ∏è Image Descriptions**  \n`Accessibility-friendly`\n\nDescribes non-text elements: `[Image: description]`\n\nContext your AI can actually use\n\n* * *\n\n## ‚öôÔ∏è Configuration\n\n[](#Ô∏è-configuration)\n\nAll settings are managed via environment variables. Tune these for your workload:\n\nVariable\n\nDefault\n\nDescription\n\n`OPENAI_API_KEY`\n\n‚Äî\n\nYour Azure OpenAI API key\n\n`AZURE_OPENAI_ENDPOINT`\n\n‚Äî\n\nYour Azure OpenAI endpoint URL\n\n`OPENAI_DEPLOYMENT_ID`\n\n‚Äî\n\nYour GPT-4 Vision deployment ID\n\n`OPENAI_API_VERSION`\n\n`gpt-4o`\n\nAPI version\n\n`BATCH_SIZE`\n\n`1`\n\nPages per OCR request (1-10). Higher = faster but less accurate\n\n`MAX_CONCURRENT_OCR_REQUESTS`\n\n`5`\n\nParallel OCR calls. Increase for throughput\n\n`MAX_CONCURRENT_PDF_CONVERSION`\n\n`4`\n\nParallel page renders. Match your CPU cores\n\n### Performance Tuning Tips\n\n[](#performance-tuning-tips)\n\n-   **High accuracy, slower:** `BATCH_SIZE=1`\n-   **Balanced:** `BATCH_SIZE=5`, `MAX_CONCURRENT_OCR_REQUESTS=10`\n-   **Maximum throughput:** `BATCH_SIZE=10`, `MAX_CONCURRENT_OCR_REQUESTS=20` (watch rate limits!)\n\n* * *\n\n## üèóÔ∏è Project Structure\n\n[](#Ô∏è-project-structure)\n\nWorld-class Python engineering with atomic modules and clean separation of concerns:\n\n```\nswift_ocr/\n‚îú‚îÄ‚îÄ __init__.py              # Package init with version\n‚îú‚îÄ‚îÄ __main__.py              # CLI entry point (python -m swift_ocr)\n‚îú‚îÄ‚îÄ app.py                   # FastAPI app factory\n‚îú‚îÄ‚îÄ config/\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îî‚îÄ‚îÄ settings.py          # Pydantic Settings (type-safe config)\n‚îú‚îÄ‚îÄ core/\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îú‚îÄ‚îÄ exceptions.py        # Custom exception hierarchy\n‚îÇ   ‚îú‚îÄ‚îÄ logging.py           # Structured logging setup\n‚îÇ   ‚îî‚îÄ‚îÄ retry.py             # Exponential backoff utilities\n‚îú‚îÄ‚îÄ schemas/\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îî‚îÄ‚îÄ ocr.py               # Pydantic request/response models\n‚îú‚îÄ‚îÄ services/\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îú‚îÄ‚îÄ ocr.py               # OpenAI Vision OCR service\n‚îÇ   ‚îî‚îÄ‚îÄ pdf.py               # PDF conversion service\n‚îî‚îÄ‚îÄ api/\n    ‚îú‚îÄ‚îÄ __init__.py\n    ‚îú‚îÄ‚îÄ deps.py              # Dependency injection\n    ‚îú‚îÄ‚îÄ exceptions.py        # FastAPI exception handlers\n    ‚îú‚îÄ‚îÄ router.py            # Route aggregation\n    ‚îî‚îÄ‚îÄ routes/\n        ‚îú‚îÄ‚îÄ __init__.py\n        ‚îú‚îÄ‚îÄ health.py        # Health check endpoints\n        ‚îî‚îÄ‚îÄ ocr.py           # OCR endpoints\n```\n\n**Key architectural decisions**\n\nPattern\n\nImplementation\n\nBenefit\n\n**Pydantic Settings**\n\n`config/settings.py`\n\nType-safe config with `.env` support and validation\n\n**Dependency Injection**\n\n`api/deps.py`\n\nTestable, swappable services\n\n**Custom Exceptions**\n\n`core/exceptions.py`\n\nRich error context with proper HTTP status codes\n\n**Retry with Backoff**\n\n`core/retry.py`\n\nHandles rate limits and transient failures\n\n**App Factory**\n\n`app.py`\n\nConfigurable app creation for testing\n\n**Typed Throughout**\n\n`py.typed` marker\n\nFull mypy compatibility\n\n* * *\n\n## üî• Common Issues & Quick Fixes\n\n[](#-common-issues--quick-fixes)\n\n**Expand for troubleshooting tips**\n\nProblem\n\nSolution\n\n**\"Missing required environment variables\"**\n\nCheck your `.env` file has all three required variables: `OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT`, `OPENAI_DEPLOYMENT_ID`\n\n**Rate limit errors (429)**\n\nReduce `MAX_CONCURRENT_OCR_REQUESTS` or `BATCH_SIZE`. The retry logic will handle temporary limits automatically.\n\n**Timeout errors**\n\nLarge PDFs take time. The system has exponential backoff built in‚Äîgive it a moment.\n\n**Garbled output**\n\nMake sure your PDF isn't password-protected or corrupted. Try opening it locally first.\n\n**Tables not formatting correctly**\n\nSome extremely complex tables may need `BATCH_SIZE=1` for best accuracy.\n\n**\"Failed to initialize OpenAI client\"**\n\nVerify your Azure endpoint URL format: `https://your-resource.openai.azure.com/`\n\n* * *\n\n## üìú License\n\n[](#-license)\n\nThis project uses **PyMuPDF** for PDF processing, which requires the **GNU AGPL v3.0** license.\n\n> **Want MIT instead?** Fork this project and swap PyMuPDF for `pdf2image` + Poppler. The rest of the code is yours to use freely.\n\n```\nGNU AFFERO GENERAL PUBLIC LICENSE\nVersion 3, 19 November 2007\n\nCopyright (C) 2024 Yiƒüit Konur\n```\n\nSee [LICENSE.md](/yigitkonur/llm-ocr/blob/main/LICENSE.md) for the full license text.\n\n* * *\n\n**Built with üî• because manually transcribing PDFs is a soul-crushing waste of time.**\n\n[Report Bug](https://github.com/yigitkonur/swift-ocr-llm-powered-pdf-to-markdown/issues) ‚Ä¢ [Request Feature](https://github.com/yigitkonur/swift-ocr-llm-powered-pdf-to-markdown/issues)\n\n## About\n\nAn open-source OCR API that leverages OpenAI's powerful language models with optimized performance techniques like parallel processing and batching to deliver high-quality text extraction from complex PDF documents. Ideal for businesses seeking efficient document digitization and data extraction solutions.\n\n### Resources\n\n[Readme](#readme-ov-file)\n\n### License\n\n[View license](#License-1-ov-file)\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n[Activity](/yigitkonur/llm-ocr/activity)\n\n### Stars\n\n[**875** stars](/yigitkonur/llm-ocr/stargazers)\n\n### Watchers\n\n[**7** watching](/yigitkonur/llm-ocr/watchers)\n\n### Forks\n\n[**62** forks](/yigitkonur/llm-ocr/forks)\n\n[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Fllm-ocr&report=yigitkonur+%28user%29)\n\n## [Releases](/yigitkonur/llm-ocr/releases)\n\nNo releases published\n\n## [Packages 0](/users/yigitkonur/packages?repo_name=llm-ocr)\n\nNo packages published  \n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n## [Contributors 2](/yigitkonur/llm-ocr/graphs/contributors)\n\n¬†¬†### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n## Languages\n\n-   [Python 100.0%](/yigitkonur/llm-ocr/search?l=python)\n\nYou can‚Äôt perform that action at this time.\n\n---\n\n## https://github.com/yigitkonur/rust-10k-req-demo\n\nGitHub - yigitkonur/rust-10k-req-demo: A high-performance Rust tool for sending API requests (to LLMs in my case) with built-in weighted load balancing, retry mechanisms, and rate limiting. Using hyper for fast request handling, it manages large volumes of asynchronous requests and is optimized for 10K request per second.                                             \n\n[Skip to content](#start-of-content)   \n\n## Navigation Menu\n\nToggle navigation\n\n[](/)\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Frust-10k-req-demo)\n\nAppearance settings\n\n  \n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n\n# Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\n Include my email address so I can be contacted\n\nCancel Submit feedback\n\n# Saved searches\n\n## Use saved searches to filter your results more quickly\n\nName  \n\nQuery \n\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\n\nCancel Create saved search\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Frust-10k-req-demo)\n\n[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=yigitkonur%2Frust-10k-req-demo)\n\nAppearance settings\n\nResetting focus\n\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\n\n[yigitkonur](/yigitkonur) / **[rust-10k-req-demo](/yigitkonur/rust-10k-req-demo)** Public\n\n-   [Notifications](/login?return_to=%2Fyigitkonur%2Frust-10k-req-demo) You must be signed in to change notification settings\n-   [Fork 1](/login?return_to=%2Fyigitkonur%2Frust-10k-req-demo)\n-   [Star 17](/login?return_to=%2Fyigitkonur%2Frust-10k-req-demo)\n    \n\nA high-performance Rust tool for sending API requests (to LLMs in my case) with built-in weighted load balancing, retry mechanisms, and rate limiting. Using hyper for fast request handling, it manages large volumes of asynchronous requests and is optimized for 10K request per second.\n\n### License\n\n[MIT license](/yigitkonur/rust-10k-req-demo/blob/main/LICENSE)\n\n[17 stars](/yigitkonur/rust-10k-req-demo/stargazers) [1 fork](/yigitkonur/rust-10k-req-demo/forks) [Branches](/yigitkonur/rust-10k-req-demo/branches) [Tags](/yigitkonur/rust-10k-req-demo/tags) [Activity](/yigitkonur/rust-10k-req-demo/activity)\n\n[Star](/login?return_to=%2Fyigitkonur%2Frust-10k-req-demo)\n\n[Notifications](/login?return_to=%2Fyigitkonur%2Frust-10k-req-demo) You must be signed in to change notification settings\n\n# yigitkonur/rust-10k-req-demo\n\n  \n\n¬†main\n\n[Branches](/yigitkonur/rust-10k-req-demo/branches)[Tags](/yigitkonur/rust-10k-req-demo/tags)\n\n[](/yigitkonur/rust-10k-req-demo/branches)[](/yigitkonur/rust-10k-req-demo/tags)\n\nGo to file\n\nCode\n\nOpen more actions menu\n\n## Folders and files\n\nName\n\nName\n\nLast commit message\n\nLast commit date\n\n## Latest commit\n\n## History\n\n[8 Commits](/yigitkonur/rust-10k-req-demo/commits/main/)\n\n[](/yigitkonur/rust-10k-req-demo/commits/main/)\n\n[benches](/yigitkonur/rust-10k-req-demo/tree/main/benches \"benches\")\n\n[benches](/yigitkonur/rust-10k-req-demo/tree/main/benches \"benches\")\n\n[examples](/yigitkonur/rust-10k-req-demo/tree/main/examples \"examples\")\n\n[examples](/yigitkonur/rust-10k-req-demo/tree/main/examples \"examples\")\n\n[src](/yigitkonur/rust-10k-req-demo/tree/main/src \"src\")\n\n[src](/yigitkonur/rust-10k-req-demo/tree/main/src \"src\")\n\n[.gitignore](/yigitkonur/rust-10k-req-demo/blob/main/.gitignore \".gitignore\")\n\n[.gitignore](/yigitkonur/rust-10k-req-demo/blob/main/.gitignore \".gitignore\")\n\n[Cargo.toml](/yigitkonur/rust-10k-req-demo/blob/main/Cargo.toml \"Cargo.toml\")\n\n[Cargo.toml](/yigitkonur/rust-10k-req-demo/blob/main/Cargo.toml \"Cargo.toml\")\n\n[LICENSE](/yigitkonur/rust-10k-req-demo/blob/main/LICENSE \"LICENSE\")\n\n[LICENSE](/yigitkonur/rust-10k-req-demo/blob/main/LICENSE \"LICENSE\")\n\n[README.md](/yigitkonur/rust-10k-req-demo/blob/main/README.md \"README.md\")\n\n[README.md](/yigitkonur/rust-10k-req-demo/blob/main/README.md \"README.md\")\n\nView all files\n\n## Repository files navigation\n\n# üî• Blaze API üî•\n\n[](#-blaze-api-)\n\n### Stop waiting for API responses. Start blazing through them.\n\n[](#stop-waiting-for-api-responses-start-blazing-through-them)\n\n**_The ultimate batch API client for your LLM workloads. It load-balances across endpoints, retries intelligently, and processes 10,000+ requests per second on a laptop._**\n\n[![crates.io](https://camo.githubusercontent.com/f70f896d47dfd3dcd1629f79429eed4f004688cbcbe044708461e07977bc73e2/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f626c617a652d6170692e7376673f7374796c653d666c61742d73717561726526636f6c6f723d344438374536)](https://crates.io/crates/blaze-api) [![rust](https://camo.githubusercontent.com/27cf849475ce885b34707dfd00b865f70a95e44b2f4ef8ebfff397225d543d77/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f727573742d312e37352b2d3444383745362e7376673f7374796c653d666c61742d737175617265)](#) ¬†¬†‚Ä¢¬†¬† [![license](https://camo.githubusercontent.com/b9394454fa0b691582af19a29fc9d773de827bf10e109544bf7b49f16e43032f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d4639413832352e7376673f7374796c653d666c61742d737175617265)](https://opensource.org/licenses/MIT) [![platform](https://camo.githubusercontent.com/be90eb7ad01a3a68618f2facaf2ae9ab2a0550276a4362e1a5167ad90411858e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d2d6d61634f535f7c5f4c696e75785f7c5f57696e646f77732d3245443537332e7376673f7374796c653d666c61742d737175617265)](#)\n\n[![zero config](https://camo.githubusercontent.com/a847dd4a8e4a6b9dd33b1d3c2878cb864756ed3170cf7a18090d79e571e4e65b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652fe29a99efb88f5f7a65726f5f636f6e6669672d776f726b735f6f75745f6f665f7468655f626f782d3245443537332e7376673f7374796c653d666f722d7468652d6261646765)](https://camo.githubusercontent.com/a847dd4a8e4a6b9dd33b1d3c2878cb864756ed3170cf7a18090d79e571e4e65b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652fe29a99efb88f5f7a65726f5f636f6e6669672d776f726b735f6f75745f6f665f7468655f626f782d3245443537332e7376673f7374796c653d666f722d7468652d6261646765) [![10k rps](https://camo.githubusercontent.com/8dbb38120b2c0d87ba8c33fdef473939a7d6f4bf5df325b644fb3c60f4783a42/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09f9a805f31304b2b5f7265712f7365632d6f6e5f6d6f646573745f68617264776172652d3245443537332e7376673f7374796c653d666f722d7468652d6261646765)](https://camo.githubusercontent.com/8dbb38120b2c0d87ba8c33fdef473939a7d6f4bf5df325b644fb3c60f4783a42/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09f9a805f31304b2b5f7265712f7365632d6f6e5f6d6f646573745f68617264776172652d3245443537332e7376673f7374796c653d666f722d7468652d6261646765)\n\n### üß≠ Quick Navigation\n\n[](#-quick-navigation)\n\n[**‚ö° Get Started**](#-get-started-in-60-seconds) ‚Ä¢ [**‚ú® Key Features**](#-feature-breakdown-the-secret-sauce) ‚Ä¢ [**üéÆ Usage & Examples**](#-usage-fire-and-forget) ‚Ä¢ [**‚öôÔ∏è Configuration**](#%EF%B8%8F-configuration) ‚Ä¢ [**üÜö Why Blaze**](#-why-blaze-slaps-other-methods)\n\n* * *\n\n**Blaze API** is the batch processor your LLM workloads deserve. Stop writing brittle Python scripts that crash at 100 req/sec. This tool acts like a fleet of pro API consumers, intelligently distributing requests across endpoints, handling failures gracefully, and maxing out your API capacity without breaking a sweat.\n\n### ‚ö°\n\n[](#)\n\n**Blazing Fast**  \n10K+ req/sec on 8 cores\n\n### üéØ\n\n[](#-1)\n\n**Smart Load Balancing**  \nWeighted distribution across endpoints\n\n### üîÑ\n\n[](#-2)\n\n**Auto Retry**  \nExponential backoff with jitter\n\n### üìä\n\n[](#-3)\n\n**Real-time Stats**  \nProgress, RPS, latency tracking\n\nHow it slaps:\n\n-   **You:** `blaze -i requests.jsonl -o results.jsonl`\n-   **Blaze:** Load balances, retries failures, tracks progress, writes results.\n-   **You:** Go grab a coffee while 100K requests complete. ‚òï\n-   **Result:** Perfectly formatted JSONL with every response. Zero babysitting.\n\n* * *\n\n## üí• Why Blaze Slaps Other Methods\n\n[](#-why-blaze-slaps-other-methods)\n\nManually scripting API requests is a vibe-killer. Blaze makes other methods look ancient.\n\n**‚ùå The Old Way (Pain)**\n\n**‚úÖ The Blaze Way (Glory)**\n\n1.  Write Python script with asyncio.\n2.  Hit GIL limits at 500 req/sec.\n3.  Script crashes, lose progress.\n4.  Add retry logic, still flaky.\n5.  Manually restart, pray it works.\n\n1.  `blaze -i data.jsonl -o out.jsonl`\n2.  Watch the progress bar fly.\n3.  Failures auto-retry with backoff.\n4.  Results stream to disk instantly.\n5.  Go grab a coffee. ‚òï\n\nWe're not just sending requests. We're building a **high-throughput, fault-tolerant pipeline** with weighted load balancing, connection pooling, and intelligent retry logic that actually respects your API provider's limits.\n\n* * *\n\n## üöÄ Get Started in 60 Seconds\n\n[](#-get-started-in-60-seconds)\n\nPlatform\n\nMethod\n\nCommand\n\nü¶Ä **All**\n\nCargo\n\n`cargo install blaze-api`\n\nüçé **macOS**\n\nHomebrew\n\n`brew install yigitkonur/tap/blaze`\n\nüêß **Linux**\n\nBinary\n\nSee [releases](https://github.com/yigitkonur/blaze-api/releases)\n\nü™ü **Windows**\n\nBinary\n\nSee [releases](https://github.com/yigitkonur/blaze-api/releases)\n\n### ü¶Ä From Source (Recommended for Development)\n\n[](#-from-source-recommended-for-development)\n\n# Clone and build\ngit clone https://github.com/yigitkonur/blaze-api.git\ncd blaze-api\ncargo build --release\n\n# Binary is at ./target/release/blaze\n\n### üì¶ From crates.io\n\n[](#-from-cratesio)\n\ncargo install blaze-api\n\n> **‚ú® Zero Config:** After installation, `blaze` is ready to go. Just point it at your JSONL file!\n\n* * *\n\n## üéÆ Usage: Fire and Forget\n\n[](#-usage-fire-and-forget)\n\nThe workflow is dead simple.\n\n### Basic Usage\n\n[](#basic-usage)\n\n# Process requests and save results\nblaze --input requests.jsonl --output results.jsonl\n\n# Short flags work too\nblaze -i requests.jsonl -o results.jsonl\n\n# High-throughput mode (10K req/sec)\nblaze -i data.jsonl -o out.jsonl --rate 10000 --workers 200\n\n### With Custom Endpoints\n\n[](#with-custom-endpoints)\n\n# Use a config file for multiple endpoints\nblaze -i requests.jsonl -o results.jsonl --config endpoints.json\n\n# Or set via environment\nexport BLAZE\\_ENDPOINT\\_URL=\"https://api.openai.com/v1/completions\"\nexport BLAZE\\_API\\_KEY=\"sk-...\"\nexport BLAZE\\_MODEL=\"gpt-4\"\nblaze -i requests.jsonl -o results.jsonl\n\n### Input Format\n\n[](#input-format)\n\nYour `requests.jsonl` file should have one JSON object per line:\n\n{\"input\": \"What is the capital of France?\"}\n{\"input\": \"Explain quantum computing in simple terms.\"}\n{\"input\": \"Write a haiku about Rust programming.\"}\n\nOr with custom request bodies:\n\n{\"body\": {\"messages\": \\[{\"role\": \"user\", \"content\": \"Hello!\"}\\], \"model\": \"gpt-4\"}}\n{\"body\": {\"messages\": \\[{\"role\": \"system\", \"content\": \"You are helpful.\"}, {\"role\": \"user\", \"content\": \"Hi!\"}\\]}}\n\n### Output Format\n\n[](#output-format)\n\nResults are written as JSONL:\n\n{\"input\": \"What is the capital of France?\", \"response\": {\"choices\": \\[...\\]}, \"metadata\": {\"endpoint\": \"...\", \"latency\\_ms\": 234, \"attempts\": 1}}\n{\"input\": \"Explain quantum computing...\", \"response\": {\"choices\": \\[...\\]}, \"metadata\": {\"endpoint\": \"...\", \"latency\\_ms\": 189, \"attempts\": 1}}\n\nErrors go to `errors.jsonl`:\n\n{\"input\": \"...\", \"error\": \"HTTP 429: Rate limit exceeded\", \"status\\_code\": 429, \"attempts\": 3}\n\n* * *\n\n## ‚ú® Feature Breakdown: The Secret Sauce\n\n[](#-feature-breakdown-the-secret-sauce)\n\nFeature\n\nWhat It Does\n\nWhy You Care\n\n**‚ö° Async Everything**  \n`Tokio runtime`\n\nNon-blocking I/O with work-stealing scheduler\n\nSaturates your CPU cores efficiently\n\n**üéØ Weighted Load Balancing**  \n`Smart distribution`\n\nRoute traffic based on endpoint capacity\n\nMax out multiple API keys simultaneously\n\n**üîÑ Exponential Backoff**  \n`With jitter`\n\nIntelligent retry with randomized delays\n\nRespects rate limits, avoids thundering herd\n\n**üìä Real-time Progress**  \n`Live stats`\n\nRPS, success rate, latency, ETA\n\nKnow exactly what's happening\n\n**üîå Connection Pooling**  \n`HTTP/2 keep-alive`\n\nReuses connections across requests\n\nEliminates TCP handshake overhead\n\n**üíæ Streaming Output**  \n`Immediate writes`\n\nResults written as they complete\n\nNever lose progress on crashes\n\n**üè• Health Tracking**  \n`Per-endpoint`\n\nAutomatic failover on errors\n\nUnhealthy endpoints get cooled off\n\n**üîß Flexible Config**  \n`CLI + ENV + JSON`\n\nConfigure via args, env vars, or files\n\nFits any workflow\n\n* * *\n\n## ‚öôÔ∏è Configuration\n\n[](#Ô∏è-configuration)\n\n### CLI Flags\n\n[](#cli-flags)\n\n```\nUSAGE:\n    blaze [OPTIONS] --input <FILE>\n\nOPTIONS:\n    -i, --input <FILE>        Path to JSONL input file [env: BLAZE_INPUT]\n    -o, --output <FILE>       Path for successful responses [env: BLAZE_OUTPUT]\n    -e, --errors <FILE>       Path for error responses [default: errors.jsonl]\n    -r, --rate <N>            Max requests per second [default: 1000]\n    -w, --workers <N>         Concurrent workers [default: 50]\n    -t, --timeout <SECS>      Request timeout [default: 30]\n    -a, --max-attempts <N>    Max retry attempts [default: 3]\n    -c, --config <FILE>       Endpoint config file (JSON)\n    -v, --verbose             Enable debug logging\n        --json-logs           Output logs as JSON\n        --no-progress         Disable progress bar\n        --dry-run             Validate config without processing\n    -h, --help                Print help\n    -V, --version             Print version\n```\n\n### Environment Variables\n\n[](#environment-variables)\n\nAll options can be set via environment variables with `BLAZE_` prefix:\n\nexport BLAZE\\_INPUT=\"requests.jsonl\"\nexport BLAZE\\_OUTPUT=\"results.jsonl\"\nexport BLAZE\\_RATE=\"5000\"\nexport BLAZE\\_WORKERS=\"100\"\nexport BLAZE\\_ENDPOINT\\_URL=\"https://api.example.com/v1/completions\"\nexport BLAZE\\_API\\_KEY=\"your-api-key\"\nexport BLAZE\\_MODEL=\"gpt-4\"\n\n### Configuration File\n\n[](#configuration-file)\n\nFor multiple endpoints, create `endpoints.json`:\n\n{\n  \"endpoints\": \\[\n    {\n      \"url\": \"https://api.openai.com/v1/completions\",\n      \"weight\": 2,\n      \"api\\_key\": \"sk-key-1\",\n      \"model\": \"gpt-4\",\n      \"max\\_concurrent\": 100\n    },\n    {\n      \"url\": \"https://api.openai.com/v1/completions\",\n      \"weight\": 1,\n      \"api\\_key\": \"sk-key-2\",\n      \"model\": \"gpt-4\",\n      \"max\\_concurrent\": 50\n    }\n  \\],\n  \"request\": {\n    \"timeout\": \"30s\",\n    \"rate\\_limit\": 5000,\n    \"workers\": 100\n  },\n  \"retry\": {\n    \"max\\_attempts\": 3,\n    \"initial\\_backoff\": \"100ms\",\n    \"max\\_backoff\": \"10s\",\n    \"multiplier\": 2.0\n  }\n}\n\nThen run:\n\nblaze -i requests.jsonl -o results.jsonl --config endpoints.json\n\n* * *\n\n## üìà Performance Tips\n\n[](#-performance-tips)\n\n### Maximize Throughput\n\n[](#maximize-throughput)\n\n# For maximum speed (adjust based on your API limits)\nblaze -i data.jsonl -o out.jsonl \\\\\n  --rate 10000 \\\\\n  --workers 200 \\\\\n  --timeout 60\n\n### Balance Load Across Keys\n\n[](#balance-load-across-keys)\n\n{\n  \"endpoints\": \\[\n    {\"url\": \"...\", \"api\\_key\": \"key-1\", \"weight\": 3, \"max\\_concurrent\": 150},\n    {\"url\": \"...\", \"api\\_key\": \"key-2\", \"weight\": 2, \"max\\_concurrent\": 100},\n    {\"url\": \"...\", \"api\\_key\": \"key-3\", \"weight\": 1, \"max\\_concurrent\": 50}\n  \\]\n}\n\n### Handle Rate Limits Gracefully\n\n[](#handle-rate-limits-gracefully)\n\n{\n  \"retry\": {\n    \"max\\_attempts\": 5,\n    \"initial\\_backoff\": \"500ms\",\n    \"max\\_backoff\": \"30s\",\n    \"multiplier\": 2.0\n  }\n}\n\n* * *\n\n## üõ†Ô∏è For Developers & Tinkerers\n\n[](#Ô∏è-for-developers--tinkerers)\n\n### Building from Source\n\n[](#building-from-source)\n\ngit clone https://github.com/yigitkonur/blaze-api.git\ncd blaze-api\n\n# Debug build\ncargo build\n\n# Release build (optimized)\ncargo build --release\n\n# Run tests\ncargo test\n\n# Run benchmarks\ncargo bench\n\n### Using as a Library\n\n[](#using-as-a-library)\n\nuse blaze\\_api::{Config, EndpointConfig, Processor};\n\n#\\[tokio::main\\]\nasync fn main() -> anyhow::Result<()\\> {\n    let config = Config {\n        endpoints: vec!\\[EndpointConfig {\n            url: \"https://api.example.com/v1/completions\".to\\_string(),\n            weight: 1,\n            api\\_key: Some(\"your-key\".to\\_string()),\n            model: Some(\"gpt-4\".to\\_string()),\n            max\\_concurrent: 100,\n        }\\],\n        ..Default::default()\n    };\n\n    let processor = Processor::new(config)?;\n    let result = processor.process\\_file(\n        \"requests.jsonl\".into(),\n        Some(\"results.jsonl\".into()),\n        \"errors.jsonl\".into(),\n        true,\n    ).await?;\n\n    result.print\\_summary();\n    Ok(())\n}\n\n### Project Structure\n\n[](#project-structure)\n\n```\nsrc/\n‚îú‚îÄ‚îÄ lib.rs        # Library entry point\n‚îú‚îÄ‚îÄ main.rs       # CLI binary\n‚îú‚îÄ‚îÄ config.rs     # Configuration management\n‚îú‚îÄ‚îÄ client.rs     # HTTP client with retry logic\n‚îú‚îÄ‚îÄ endpoint.rs   # Load balancer implementation\n‚îú‚îÄ‚îÄ processor.rs  # Main processing orchestration\n‚îú‚îÄ‚îÄ request.rs    # Request/response types\n‚îú‚îÄ‚îÄ tracker.rs    # Statistics tracking\n‚îî‚îÄ‚îÄ error.rs      # Error types\n```\n\n* * *\n\n## üî• Common Issues & Quick Fixes\n\n[](#-common-issues--quick-fixes)\n\n**Expand for troubleshooting tips**\n\nProblem\n\nSolution\n\n**\"Too many open files\"**\n\nIncrease ulimit: `ulimit -n 65535`\n\n**Connection timeouts**\n\nIncrease `--timeout` or reduce `--workers`\n\n**Rate limit errors (429)**\n\nLower `--rate` or add more API keys\n\n**Memory usage high**\n\nReduce `--workers` for large requests\n\n**Progress bar not showing**\n\nDon't pipe output, or use `--no-progress --json-logs`\n\n**Build Issues:**\n\nProblem\n\nSolution\n\n**OpenSSL errors**\n\nInstall OpenSSL dev: `apt install libssl-dev` or use `--features rustls`\n\n**Rust version error**\n\nUpdate Rust: `rustup update stable` (requires 1.75+)\n\n* * *\n\n## ü§ù Contributing\n\n[](#-contributing)\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n# Fork the repo, then:\ngit clone https://github.com/YOUR\\_USERNAME/blaze-api.git\ncd blaze-api\ncargo test\n# Make your changes\ncargo fmt\ncargo clippy\ncargo test\n# Submit PR\n\n* * *\n\n## üìÑ License\n\n[](#-license)\n\nMIT ¬© [Yiƒüit Konur](https://github.com/yigitkonur)\n\n* * *\n\n**Built with üî• because waiting for API responses is a soul-crushing waste of time.**\n\n[‚¨Ü Back to Top](#-blaze-api-)\n\n## About\n\nA high-performance Rust tool for sending API requests (to LLMs in my case) with built-in weighted load balancing, retry mechanisms, and rate limiting. Using hyper for fast request handling, it manages large volumes of asynchronous requests and is optimized for 10K request per second.\n\n### Resources\n\n[Readme](#readme-ov-file)\n\n### License\n\n[MIT license](#MIT-1-ov-file)\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n[Activity](/yigitkonur/rust-10k-req-demo/activity)\n\n### Stars\n\n[**17** stars](/yigitkonur/rust-10k-req-demo/stargazers)\n\n### Watchers\n\n[**1** watching](/yigitkonur/rust-10k-req-demo/watchers)\n\n### Forks\n\n[**1** fork](/yigitkonur/rust-10k-req-demo/forks)\n\n[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Frust-10k-req-demo&report=yigitkonur+%28user%29)\n\n## [Releases](/yigitkonur/rust-10k-req-demo/releases)\n\nNo releases published\n\n## [Packages 0](/users/yigitkonur/packages?repo_name=rust-10k-req-demo)\n\nNo packages published  \n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n## Languages\n\n-   [Rust 100.0%](/yigitkonur/rust-10k-req-demo/search?l=rust)\n\nYou can‚Äôt perform that action at this time.\n\n---\n\n## https://github.com/yigitkonur/telnyx-llm-call\n\nGitHub - yigitkonur/telnyx-llm-call: A script that uses Telnyx API to make bulk calls to a given list of numbers and analyzes the audio recordings with Whisper. This way, we don‚Äôt have to read all the transcriptions.                                             \n\n[Skip to content](#start-of-content)   \n\n## Navigation Menu\n\nToggle navigation\n\n[](/)\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Ftelnyx-llm-call)\n\nAppearance settings\n\n  \n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n\n# Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\n Include my email address so I can be contacted\n\nCancel Submit feedback\n\n# Saved searches\n\n## Use saved searches to filter your results more quickly\n\nName  \n\nQuery \n\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\n\nCancel Create saved search\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Ftelnyx-llm-call)\n\n[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=yigitkonur%2Ftelnyx-llm-call)\n\nAppearance settings\n\nResetting focus\n\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\n\n[yigitkonur](/yigitkonur) / **[telnyx-llm-call](/yigitkonur/telnyx-llm-call)** Public\n\n-   [Notifications](/login?return_to=%2Fyigitkonur%2Ftelnyx-llm-call) You must be signed in to change notification settings\n-   [Fork 23](/login?return_to=%2Fyigitkonur%2Ftelnyx-llm-call)\n-   [Star 136](/login?return_to=%2Fyigitkonur%2Ftelnyx-llm-call)\n    \n\nA script that uses Telnyx API to make bulk calls to a given list of numbers and analyzes the audio recordings with Whisper. This way, we don‚Äôt have to read all the transcriptions.\n\n[136 stars](/yigitkonur/telnyx-llm-call/stargazers) [23 forks](/yigitkonur/telnyx-llm-call/forks) [Branches](/yigitkonur/telnyx-llm-call/branches) [Tags](/yigitkonur/telnyx-llm-call/tags) [Activity](/yigitkonur/telnyx-llm-call/activity)\n\n[Star](/login?return_to=%2Fyigitkonur%2Ftelnyx-llm-call)\n\n[Notifications](/login?return_to=%2Fyigitkonur%2Ftelnyx-llm-call) You must be signed in to change notification settings\n\n# yigitkonur/telnyx-llm-call\n\n  \n\n¬†main\n\n[Branches](/yigitkonur/telnyx-llm-call/branches)[Tags](/yigitkonur/telnyx-llm-call/tags)\n\n[](/yigitkonur/telnyx-llm-call/branches)[](/yigitkonur/telnyx-llm-call/tags)\n\nGo to file\n\nCode\n\nOpen more actions menu\n\n## Folders and files\n\nName\n\nName\n\nLast commit message\n\nLast commit date\n\n## Latest commit\n\n## History\n\n[6 Commits](/yigitkonur/telnyx-llm-call/commits/main/)\n\n[](/yigitkonur/telnyx-llm-call/commits/main/)\n\n[src/telnyx\\_transcribe](/yigitkonur/telnyx-llm-call/tree/main/src/telnyx_transcribe \"This path skips through empty directories\")\n\n[src/telnyx\\_transcribe](/yigitkonur/telnyx-llm-call/tree/main/src/telnyx_transcribe \"This path skips through empty directories\")\n\n[tests](/yigitkonur/telnyx-llm-call/tree/main/tests \"tests\")\n\n[tests](/yigitkonur/telnyx-llm-call/tree/main/tests \"tests\")\n\n[.env.example](/yigitkonur/telnyx-llm-call/blob/main/.env.example \".env.example\")\n\n[.env.example](/yigitkonur/telnyx-llm-call/blob/main/.env.example \".env.example\")\n\n[.gitignore](/yigitkonur/telnyx-llm-call/blob/main/.gitignore \".gitignore\")\n\n[.gitignore](/yigitkonur/telnyx-llm-call/blob/main/.gitignore \".gitignore\")\n\n[README.md](/yigitkonur/telnyx-llm-call/blob/main/README.md \"README.md\")\n\n[README.md](/yigitkonur/telnyx-llm-call/blob/main/README.md \"README.md\")\n\n[pyproject.toml](/yigitkonur/telnyx-llm-call/blob/main/pyproject.toml \"pyproject.toml\")\n\n[pyproject.toml](/yigitkonur/telnyx-llm-call/blob/main/pyproject.toml \"pyproject.toml\")\n\n[requirements.txt](/yigitkonur/telnyx-llm-call/blob/main/requirements.txt \"requirements.txt\")\n\n[requirements.txt](/yigitkonur/telnyx-llm-call/blob/main/requirements.txt \"requirements.txt\")\n\nView all files\n\n## Repository files navigation\n\n# üéôÔ∏è telnyx-transcribe üéôÔ∏è\n\n[](#Ô∏è-telnyx-transcribe-Ô∏è)\n\n### Stop manually transcribing calls. Start automating everything.\n\n[](#stop-manually-transcribing-calls-start-automating-everything)\n\n**_The ultimate call-and-transcribe toolkit. It dials your list, plays your audio, records everything, and transcribes it all using OpenAI Whisper ‚Äî automatically._**\n\n[![pypi](https://camo.githubusercontent.com/12cdf33998a3ef4c8d3a8371e886cfdbca6a332a50401355e328ff7ea4b91b93/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f74656c6e79782d7472616e7363726962652e7376673f7374796c653d666c61742d73717561726526636f6c6f723d344438374536)](https://pypi.org/project/telnyx-transcribe/) [![python](https://camo.githubusercontent.com/4808218212ece46251343f2523af0fdfb557a5bef0edc616a82c5480e8cd2da2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e31302b2d3444383745362e7376673f7374796c653d666c61742d737175617265)](#) ¬†¬†‚Ä¢¬†¬† [![license](https://camo.githubusercontent.com/b9394454fa0b691582af19a29fc9d773de827bf10e109544bf7b49f16e43032f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d4639413832352e7376673f7374796c653d666c61742d737175617265)](https://opensource.org/licenses/MIT) [![platform](https://camo.githubusercontent.com/be90eb7ad01a3a68618f2facaf2ae9ab2a0550276a4362e1a5167ad90411858e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d2d6d61634f535f7c5f4c696e75785f7c5f57696e646f77732d3245443537332e7376673f7374796c653d666c61742d737175617265)](#)\n\n[![automated](https://camo.githubusercontent.com/f2dc5aa70c726f1da67ecfc436103d09e4ef67c12b953b8d41c3212d779a363c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09fa4965f66756c6c795f6175746f6d617465642d6469616c5f746f5f7472616e7363726970742d3245443537332e7376673f7374796c653d666f722d7468652d6261646765)](https://camo.githubusercontent.com/f2dc5aa70c726f1da67ecfc436103d09e4ef67c12b953b8d41c3212d779a363c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09fa4965f66756c6c795f6175746f6d617465642d6469616c5f746f5f7472616e7363726970742d3245443537332e7376673f7374796c653d666f722d7468652d6261646765) [![whisper powered](https://camo.githubusercontent.com/75a3bf0139d4e175e81731e26845b6c8d4ac6cc94bb83cb81cff42de12113e27/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09fa7a05f776869737065725f706f77657265642d73746174655f6f665f6172745f5354542d3245443537332e7376673f7374796c653d666f722d7468652d6261646765)](https://camo.githubusercontent.com/75a3bf0139d4e175e81731e26845b6c8d4ac6cc94bb83cb81cff42de12113e27/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09fa7a05f776869737065725f706f77657265642d73746174655f6f665f6172745f5354542d3245443537332e7376673f7374796c653d666f722d7468652d6261646765)\n\n### üß≠ Quick Navigation\n\n[](#-quick-navigation)\n\n[**‚ö° Get Started**](#-get-started-in-60-seconds) ‚Ä¢ [**‚ú® Key Features**](#-feature-breakdown-the-secret-sauce) ‚Ä¢ [**üéÆ Usage & Examples**](#-usage-fire-and-forget) ‚Ä¢ [**‚öôÔ∏è Configuration**](#%EF%B8%8F-configuration) ‚Ä¢ [**üÜö Why This Slaps**](#-why-this-slaps-other-methods)\n\n* * *\n\n**telnyx-transcribe** is the automated phone assistant your workflow has been missing. Stop manually calling people, recording conversations, and typing out transcripts. This tool does it all ‚Äî dials your list, plays your audio message, records the responses, and delivers beautiful transcriptions using OpenAI's Whisper, the most accurate speech-to-text model available.\n\n### üìû\n\n[](#)\n\n**Bulk Calling**  \nDial hundreds in parallel\n\n### üîä\n\n[](#-1)\n\n**Auto Playback**  \nPlay your audio message\n\n### üéôÔ∏è\n\n[](#Ô∏è)\n\n**Smart Recording**  \nCapture every response\n\n### üß†\n\n[](#-2)\n\n**Whisper Transcription**  \nState-of-the-art accuracy\n\nHow it slaps:\n\n-   **You:** `telnyx-transcribe call numbers.txt`\n-   **Tool:** Dials all numbers, plays audio, records, transcribes.\n-   **You:** Check `results.tsv` for all transcriptions.\n-   **Result:** Hours of work done in minutes. Go grab a coffee. ‚òï\n\n* * *\n\n## üí• Why This Slaps Other Methods\n\n[](#-why-this-slaps-other-methods)\n\nManually managing calls and transcriptions is a vibe-killer. `telnyx-transcribe` makes other methods look ancient.\n\n**‚ùå The Old Way (Pain)**\n\n**‚úÖ The telnyx-transcribe Way (Glory)**\n\n1.  Manually dial each number.\n2.  Play your message, wait for response.\n3.  Fumble with recording software.\n4.  Upload recordings somewhere.\n5.  Manually transcribe or use slow tools.\n6.  Copy results into a spreadsheet.\n\n1.  `telnyx-transcribe call numbers.txt`\n2.  Wait for completion notification.\n3.  Open `results.tsv`.\n4.  All transcriptions, ready to go.\n5.  Go do something actually important. üöÄ\n\nWe're not just making calls. We're building a **fully automated pipeline** with concurrent call handling, automatic webhook processing, intelligent retry logic, and state-of-the-art transcription that handles accents, background noise, and multiple languages like a champ.\n\n* * *\n\n## üöÄ Get Started in 60 Seconds\n\n[](#-get-started-in-60-seconds)\n\nThe `telnyx-transcribe` command (or just `tt`) will be available in your terminal after installation.\n\nMethod\n\nCommand\n\n**pip**\n\n`pip install telnyx-transcribe`\n\n**pipx**\n\n`pipx install telnyx-transcribe`\n\n**From source**\n\n`pip install -e .`\n\n### Using pip (Recommended)\n\n[](#using-pip-recommended)\n\n# Install the package\npip install telnyx-transcribe\n\n# Verify installation\ntelnyx-transcribe --version\n\n### Using pipx (Isolated Environment)\n\n[](#using-pipx-isolated-environment)\n\n# Install pipx if you don't have it\npython3 -m pip install --user pipx\npython3 -m pipx ensurepath\n\n# Install telnyx-transcribe\npipx install telnyx-transcribe\n\n### From Source\n\n[](#from-source)\n\n# Clone the repo\ngit clone https://github.com/yigitkonur/telnyx-transcribe.git\ncd telnyx-transcribe\n\n# Create virtual environment\npython3 -m venv venv\nsource venv/bin/activate  # On Windows: venv\\\\Scripts\\\\activate\n\n# Install in development mode\npip install -e \".\\[dev\\]\"\n\n> **‚ú® Pro Tip:** Use `tt` as a shorthand for `telnyx-transcribe` ‚Äî both commands work!\n\n* * *\n\n## üéÆ Usage: Fire and Forget\n\n[](#-usage-fire-and-forget)\n\nThe workflow is dead simple.\n\n### üìû Make Calls & Transcribe\n\n[](#-make-calls--transcribe)\n\n**1\\. Create your numbers file** (one E.164 number per line):\n\n```\n+14155551234\n+14155551235\n+14155551236\n```\n\n**2\\. Run the command:**\n\ntelnyx-transcribe call numbers.txt\n\n**3\\. Check your results:**\n\ncat results.tsv\n\nThat's it. All calls made, recorded, and transcribed.\n\n### üéß Standalone Transcription\n\n[](#-standalone-transcription)\n\nAlready have audio files? Transcribe them directly without making calls:\n\n# Transcribe a single file\ntelnyx-transcribe transcribe recording.mp3\n\n# Transcribe all files in a directory\ntelnyx-transcribe transcribe ./recordings/\n\n# With language hint for better accuracy\ntelnyx-transcribe transcribe ./recordings/ --language en\n\n**Supported formats:** MP3, MP4, WAV, M4A, WEBM, OGG, FLAC, MPEG, MPGA\n\n### üåê Run Webhook Server Only\n\n[](#-run-webhook-server-only)\n\nNeed just the webhook server for incoming Telnyx events?\n\n# Start server on default port (5000)\ntelnyx-transcribe server\n\n# Custom port and host\ntelnyx-transcribe server --port 8080 --host 0.0.0.0\n\n### ‚úÖ Validate Configuration\n\n[](#-validate-configuration)\n\nCheck if everything is set up correctly before running:\n\ntelnyx-transcribe validate\n\n* * *\n\n## ‚ú® Feature Breakdown: The Secret Sauce\n\n[](#-feature-breakdown-the-secret-sauce)\n\nFeature\n\nWhat It Does\n\nWhy You Care\n\n**üìû Bulk Calling**  \n`Concurrent dialing`\n\nDials multiple numbers in parallel using thread pool\n\nProcess hundreds of calls in the time of one\n\n**üîä Auto Playback**  \n`Custom audio`\n\nPlays your audio file when call is answered\n\nDeliver consistent messages every time\n\n**üéôÔ∏è Smart Recording**  \n`Automatic capture`\n\nStarts recording immediately on answer\n\nNever miss a response\n\n**üß† Whisper AI**  \n`State-of-the-art STT`\n\nUses OpenAI's Whisper for transcription\n\nHandles accents, noise, multiple languages\n\n**üîÑ Auto Retry**  \n`Exponential backoff`\n\nAutomatically retries failed API calls\n\nResilient to network hiccups\n\n**üìä TSV Output**  \n`Ready for analysis`\n\nStructured output with all call details\n\nImport directly into Excel, Sheets, or scripts\n\n**üåê Webhook Server**  \n`Flask-powered`\n\nHandles Telnyx events in real-time\n\nSeamless integration with Telnyx platform\n\n**‚öôÔ∏è ENV Config**  \n`Zero hardcoding`\n\nAll secrets via environment variables\n\nSecure, 12-factor app compliant\n\n* * *\n\n## ‚öôÔ∏è Configuration\n\n[](#Ô∏è-configuration)\n\nAll configuration is done via environment variables. Create a `.env` file or export them directly.\n\n### Required Variables\n\n[](#required-variables)\n\n# Telnyx API credentials\nTELNYX\\_API\\_KEY=your\\_telnyx\\_api\\_key\nTELNYX\\_CONNECTION\\_ID=your\\_connection\\_id\nTELNYX\\_FROM\\_NUMBER=+1234567890\n\n# OpenAI API key for Whisper\nOPENAI\\_API\\_KEY=your\\_openai\\_api\\_key\n\n# Audio file to play during calls\nAUDIO\\_URL=https://example.com/your-message.mp3\n\n### Optional Variables\n\n[](#optional-variables)\n\n# Server settings\nWEBHOOK\\_HOST=0.0.0.0       # Default: 0.0.0.0\nWEBHOOK\\_PORT=5000          # Default: 5000\n\n# Output settings\nOUTPUT\\_FILE=results.tsv    # Default: results.tsv\n\n# Performance tuning\nMAX\\_WORKERS=5              # Default: 5 concurrent calls\nMAX\\_RETRIES=10             # Default: 10 retries\nRETRY\\_DELAY=2.0            # Default: 2 seconds base delay\n\n# Recording settings\nRECORDING\\_FORMAT=mp3       # Default: mp3\nRECORDING\\_CHANNELS=single  # Default: single\n\n### Quick Setup\n\n[](#quick-setup)\n\n# Copy the example env file\ncp .env.example .env\n\n# Edit with your credentials\nnano .env\n\n# Validate configuration\ntelnyx-transcribe validate\n\n* * *\n\n## üîë API Key Setup Guides\n\n[](#-api-key-setup-guides)\n\n**üìû Telnyx API ‚Äî Pay-as-you-go calling**\n\n### What you get\n\n[](#what-you-get)\n\n-   Programmable voice API for making/receiving calls\n-   Call control, recording, and webhook events\n\n### Setup Steps\n\n[](#setup-steps)\n\n1.  Go to [portal.telnyx.com](https://portal.telnyx.com)\n2.  Sign up and verify your account\n3.  Create a **Call Control Application**:\n    -   Navigate to \"Call Control\" ‚Üí \"Applications\"\n    -   Create new application\n    -   Set your webhook URL (e.g., `https://your-server.com/webhook`)\n4.  Get a phone number:\n    -   Navigate to \"Numbers\" ‚Üí \"Buy Numbers\"\n    -   Purchase a number with voice capability\n    -   Assign it to your Call Control application\n5.  Get your credentials:\n    -   **API Key**: \"API Keys\" section\n    -   **Connection ID**: Your Call Control application's connection ID\n    -   **From Number**: The number you purchased\n\n### Add to `.env`:\n\n[](#add-to-env)\n\nTELNYX\\_API\\_KEY=KEY0123456789...\nTELNYX\\_CONNECTION\\_ID=1234567890\nTELNYX\\_FROM\\_NUMBER=+14155551234\n\n**üß† OpenAI API ‚Äî Whisper transcription**\n\n### What you get\n\n[](#what-you-get-1)\n\n-   Access to Whisper speech-to-text model\n-   State-of-the-art transcription accuracy\n-   Multi-language support\n\n### Setup Steps\n\n[](#setup-steps-1)\n\n1.  Go to [platform.openai.com](https://platform.openai.com)\n2.  Sign up or log in\n3.  Navigate to [API Keys](https://platform.openai.com/api-keys)\n4.  Click \"Create new secret key\"\n5.  Copy the key (starts with `sk-`)\n\n### Add to `.env`:\n\n[](#add-to-env-1)\n\nOPENAI\\_API\\_KEY=sk-...\n\n### Pricing\n\n[](#pricing)\n\n-   Whisper API: $0.006 per minute of audio\n-   A 5-minute recording costs ~$0.03\n\n* * *\n\n## üèóÔ∏è Project Structure\n\n[](#Ô∏è-project-structure)\n\n```\ntelnyx-transcribe/\n‚îú‚îÄ‚îÄ src/telnyx_transcribe/\n‚îÇ   ‚îú‚îÄ‚îÄ cli.py               # Typer CLI commands\n‚îÇ   ‚îú‚îÄ‚îÄ app.py               # Flask application factory\n‚îÇ   ‚îú‚îÄ‚îÄ config.py            # Settings management\n‚îÇ   ‚îú‚îÄ‚îÄ models.py            # Data models (Call, TranscriptionResult)\n‚îÇ   ‚îú‚îÄ‚îÄ exceptions.py        # Custom exceptions\n‚îÇ   ‚îú‚îÄ‚îÄ services/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ call_service.py          # Telnyx call management\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transcription_service.py # OpenAI Whisper integration\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ output_service.py        # TSV/CSV output handling\n‚îÇ   ‚îú‚îÄ‚îÄ webhooks/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ handlers.py      # Telnyx webhook processing\n‚îÇ   ‚îî‚îÄ‚îÄ utils/\n‚îÇ       ‚îú‚îÄ‚îÄ logging.py       # Logging configuration\n‚îÇ       ‚îî‚îÄ‚îÄ console.py       # Rich console output\n‚îú‚îÄ‚îÄ tests/                   # Test suite\n‚îú‚îÄ‚îÄ pyproject.toml          # Project configuration\n‚îú‚îÄ‚îÄ requirements.txt        # Dependencies\n‚îú‚îÄ‚îÄ .env.example            # Example environment file\n‚îî‚îÄ‚îÄ README.md               # This file\n```\n\n* * *\n\n## üõ†Ô∏è For Developers & Tinkerers\n\n[](#Ô∏è-for-developers--tinkerers)\n\n### Running Tests\n\n[](#running-tests)\n\n# Install dev dependencies\npip install -e \".\\[dev\\]\"\n\n# Run tests\npytest\n\n# Run with coverage\npytest --cov=telnyx\\_transcribe\n\n# Type checking\nmypy src/\n\n# Linting\nruff check src/\n\n### Using as a Library\n\n[](#using-as-a-library)\n\nfrom telnyx\\_transcribe import Settings\nfrom telnyx\\_transcribe.services import CallService, TranscriptionService\n\n\\# Configure settings\nsettings \\= Settings(\n    telnyx\\_api\\_key\\=\"your\\_key\",\n    openai\\_api\\_key\\=\"your\\_key\",\n    \\# ... other settings\n)\n\n\\# Use services directly\ncall\\_service \\= CallService(settings)\ncall \\= call\\_service.initiate\\_call(\"+14155551234\")\n\ntranscription\\_service \\= TranscriptionService(settings)\nresult \\= transcription\\_service.transcribe\\_file(\"recording.mp3\")\nprint(result.text)\n\n* * *\n\n## üî• Common Issues & Quick Fixes\n\n[](#-common-issues--quick-fixes)\n\n**Expand for troubleshooting tips**\n\nProblem\n\nSolution\n\n**`command not found: telnyx-transcribe`**\n\nRestart your terminal or run `pip install --upgrade telnyx-transcribe`\n\n**`TELNYX_API_KEY is required`**\n\nCreate a `.env` file with your credentials. Run `telnyx-transcribe validate` to check.\n\n**Webhook events not received**\n\nEnsure your webhook URL is publicly accessible. Use ngrok for local testing: `ngrok http 5000`\n\n**Transcription fails**\n\nCheck your `OPENAI_API_KEY` is valid and has credits. Verify audio format is supported.\n\n**Calls not connecting**\n\nVerify `TELNYX_FROM_NUMBER` is assigned to your Call Control application. Check number format (E.164).\n\n**Recording URL not available**\n\nTelnyx needs time to process recordings. The webhook handles this automatically with retries.\n\n**Debugging tips:**\n\n# Run with verbose logging\ntelnyx-transcribe --verbose call numbers.txt\n\n# Check your configuration\ntelnyx-transcribe validate\n\n# Test webhook server locally\ntelnyx-transcribe server --port 5000\n# Then use ngrok: ngrok http 5000\n\n* * *\n\n## üìú Backstory\n\n[](#-backstory)\n\nThis project started from a simple need ‚Äî automate phone-based surveys and transcribe the responses. What began as a quick script evolved into a full-featured, production-ready tool.\n\n> [https://twitter.com/yigitkonur/status/1654827917845860353](https://twitter.com/yigitkonur/status/1654827917845860353)\n\n* * *\n\n## üìÑ License\n\n[](#-license)\n\nMIT ¬© [Yiƒüit Konur](https://github.com/yigitkonur)\n\n* * *\n\n**Built with üî• because manually transcribing phone calls is a soul-crushing waste of time.**\n\n[Report Bug](https://github.com/yigitkonur/telnyx-transcribe/issues) ‚Ä¢ [Request Feature](https://github.com/yigitkonur/telnyx-transcribe/issues) ‚Ä¢ [Contribute](https://github.com/yigitkonur/telnyx-transcribe/pulls)\n\n## About\n\nA script that uses Telnyx API to make bulk calls to a given list of numbers and analyzes the audio recordings with Whisper. This way, we don‚Äôt have to read all the transcriptions.\n\n### Resources\n\n[Readme](#readme-ov-file)\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n[Activity](/yigitkonur/telnyx-llm-call/activity)\n\n### Stars\n\n[**136** stars](/yigitkonur/telnyx-llm-call/stargazers)\n\n### Watchers\n\n[**4** watching](/yigitkonur/telnyx-llm-call/watchers)\n\n### Forks\n\n[**23** forks](/yigitkonur/telnyx-llm-call/forks)\n\n[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Ftelnyx-llm-call&report=yigitkonur+%28user%29)\n\n## [Releases](/yigitkonur/telnyx-llm-call/releases)\n\nNo releases published\n\n## [Packages 0](/users/yigitkonur/packages?repo_name=telnyx-llm-call)\n\nNo packages published  \n\n## Languages\n\n-   [Python 100.0%](/yigitkonur/telnyx-llm-call/search?l=python)\n\nYou can‚Äôt perform that action at this time."
    }
  ]
}
