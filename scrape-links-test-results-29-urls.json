[Terminal output truncated: ~32KB dropped from beginning]
g/branches) [Tags](/yigitkonur/n8n-docker-ffmpeg/tags) [Activity](/yigitkonur/n8n-docker-ffmpeg/activity)\n\n[Star](/login?return_to=%2Fyigitkonur%2Fn8n-docker-ffmpeg)\n\n[Notifications](/login?return_to=%2Fyigitkonur%2Fn8n-docker-ffmpeg) You must be signed in to change notification settings\n\n# yigitkonur/n8n-docker-ffmpeg\n\n  \n\nÂ main\n\n[Branches](/yigitkonur/n8n-docker-ffmpeg/branches)[Tags](/yigitkonur/n8n-docker-ffmpeg/tags)\n\n[](/yigitkonur/n8n-docker-ffmpeg/branches)[](/yigitkonur/n8n-docker-ffmpeg/tags)\n\nGo to file\n\nCode\n\nOpen more actions menu\n\n## Folders and files\n\nName\n\nName\n\nLast commit message\n\nLast commit date\n\n## Latest commit\n\n## History\n\n[6 Commits](/yigitkonur/n8n-docker-ffmpeg/commits/main/)\n\n[](/yigitkonur/n8n-docker-ffmpeg/commits/main/)\n\n[.env](/yigitkonur/n8n-docker-ffmpeg/blob/main/.env \".env\")\n\n[.env](/yigitkonur/n8n-docker-ffmpeg/blob/main/.env \".env\")\n\n[Dockerfile](/yigitkonur/n8n-docker-ffmpeg/blob/main/Dockerfile \"Dockerfile\")\n\n[Dockerfile](/yigitkonur/n8n-docker-ffmpeg/blob/main/Dockerfile \"Dockerfile\")\n\n[README.md](/yigitkonur/n8n-docker-ffmpeg/blob/main/README.md \"README.md\")\n\n[README.md](/yigitkonur/n8n-docker-ffmpeg/blob/main/README.md \"README.md\")\n\n[docker-compose.yml](/yigitkonur/n8n-docker-ffmpeg/blob/main/docker-compose.yml \"docker-compose.yml\")\n\n[docker-compose.yml](/yigitkonur/n8n-docker-ffmpeg/blob/main/docker-compose.yml \"docker-compose.yml\")\n\nView all files\n\n## Repository files navigation\n\n# n8n with ffmpeg and Docker Compose\n\n[](#n8n-with-ffmpeg-and-docker-compose)\n\nThis repository provides a Docker Compose setup for running n8n with ffmpeg support. It also includes instructions for setting up the service to run on system startup using systemd.\n\n## Prerequisites\n\n[](#prerequisites)\n\n-   Docker: [Install Docker](https://docs.docker.com/get-docker/)\n-   Docker Compose: [Install Docker Compose](https://docs.docker.com/compose/install/)\n\n## Setup\n\n[](#setup)\n\n### 1\\. Clone the Repository\n\n[](#1-clone-the-repository)\n\nOpen a terminal and run the following commands:\n\ngit clone https://github.com/yourusername/n8n-docker-ffmpeg.git\ncd n8n-docker-ffmpeg\n\n### 2\\. Create a `.env` File\n\n[](#2-create-a-env-file)\n\nCreate a file named `.env` in the root of the repository and add the following variables:\n\nN8N\\_HOST\\=n8n.local\nN8N\\_PORT\\=5678\nN8N\\_PROTOCOL\\=https\nNODE\\_ENV\\=production\nWEBHOOK\\_URL\\=https://n8n.local/\nGENERIC\\_TIMEZONE\\=America/New\\_York\n\n### 3\\. Build and Run the Containers\n\n[](#3-build-and-run-the-containers)\n\nBuild the Docker containers and start the services:\n\ndocker-compose build --no-cache\ndocker-compose up -d\n\n### 4\\. Access n8n\n\n[](#4-access-n8n)\n\nOpen your browser and go to `https://n8n.local`.\n\n## Setting up as a Systemd Service\n\n[](#setting-up-as-a-systemd-service)\n\nTo ensure the Docker Compose services start on system boot, follow these steps:\n\n### 1\\. Create the Systemd Service File\n\n[](#1-create-the-systemd-service-file)\n\nCreate a new systemd service file:\n\nsudo nano /etc/systemd/system/docker-compose.service\n\nCopy the following content into the file:\n\n\\[Unit\\]\nDescription\\=Docker Compose Service\nAfter\\=network.target docker.service\nRequires\\=docker.service\n\n\\[Service\\]\nType\\=oneshot\nUser\\=root\nWorkingDirectory\\=/path/to/your/n8n-docker-ffmpeg\nExecStart\\=/usr/bin/docker-compose build --no-cache\nExecStartPost\\=/usr/bin/docker-compose up -d\nRemainAfterExit\\=true\n\n\\[Install\\]\nWantedBy\\=multi-user.target\n\n### 2\\. Reload Systemd and Enable the Service\n\n[](#2-reload-systemd-and-enable-the-service)\n\nsudo systemctl daemon-reload\nsudo systemctl enable docker-compose.service\nsudo systemctl start docker-compose.service\n\n### Manual Startup\n\n[](#manual-startup)\n\nIf you prefer to start the services manually, navigate to the project directory and run:\n\ncd /path/to/your/n8n-docker-ffmpeg\ndocker-compose build --no-cache\ndocker-compose up -d\n\n## Volumes\n\n[](#volumes)\n\n-   `caddy_data`: Stores Caddy server data.\n-   `n8n_data`: Stores n8n workflow data.\n\n## Additional Information\n\n[](#additional-information)\n\n-   The `Dockerfile` installs Docker CLI and ffmpeg inside the n8n container to enable additional functionality.\n-   Ensure that the `caddy_config` directory and `Caddyfile` are correctly set up in your project directory.\n\nFor more detailed instructions and troubleshooting, please refer to the official documentation of [Docker](https://docs.docker.com/) and [n8n](https://docs.n8n.io/).\n\n### Using n8n with ffmpeg\n\n[](#using-n8n-with-ffmpeg)\n\nWith ffmpeg installed in your n8n Docker container, you can leverage the power of ffmpeg directly within your n8n workflows. This allows you to process media files as part of your automation sequences.\n\n#### Example: Convert MP4 to MP3\n\n[](#example-convert-mp4-to-mp3)\n\nIn this example, we'll demonstrate how to use the Execute Command node in n8n to convert an MP4 video file to an MP3 audio file.\n\n1.  **Add the Execute Command Node**\n    \n    -   Open your n8n editor and create a new workflow.\n    -   Add an \"Execute Command\" node to your workflow.\n2.  **Configure the Execute Command Node**\n    \n    -   Set the \"Command\" field to the ffmpeg command for converting MP4 to MP3.\n        \n    -   Example command:\n        \n        ffmpeg -i /files/input-video.mp4 -q:a 0 -map a /files/output-audio.mp3\n        \n    -   Here's the detailed configuration:\n        \n        -   **Command**: `ffmpeg`\n        -   **Parameters**: `-i /files/input-video.mp4 -q:a 0 -map a /files/output-audio.mp3`\n3.  **Place Input File and Define Output Location**\n    \n    -   Ensure the input MP4 file (`input-video.mp4`) is placed in the `/files` directory within your n8n container.\n    -   The converted MP3 file (`output-audio.mp3`) will be saved in the same directory.\n4.  **Execute the Workflow**\n    \n    -   Execute the workflow to run the ffmpeg command.\n    -   Check the `/files` directory for the newly created `output-audio.mp3` file.\n\n#### Detailed Steps\n\n[](#detailed-steps)\n\n1.  **Place the Input File**: Copy your MP4 file to the `local_files` directory on your host machine, which maps to `/files` inside the n8n container.\n    \n    cp /path/to/your/input-video.mp4 /path/to/n8n-docker-ffmpeg/local\\_files/\n    \n2.  **Create and Configure the Workflow**: Follow the steps above to create a workflow in n8n and configure the Execute Command node.\n    \n3.  **Run the Workflow**: Execute your workflow in n8n. After the workflow completes, you can find the converted MP3 file in the `local_files` directory.\n    \n\n### Benefits\n\n[](#benefits)\n\n-   **Automation**: Automate media file conversions as part of larger workflows.\n-   **Flexibility**: Use any ffmpeg command within n8n for various media processing tasks.\n-   **Ease of Use**: Simplify media processing tasks without leaving your n8n environment.\n\nBy following these steps, you can easily incorporate media processing into your n8n workflows, leveraging the powerful capabilities of ffmpeg directly within your automation sequences.\n\n## About\n\nRepository for setting up n8n with ffmpeg using Docker Compose, including beginner-friendly instructions and systemd service configuration for automatic startup.\n\n### Resources\n\n[Readme](#readme-ov-file)\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n[Activity](/yigitkonur/n8n-docker-ffmpeg/activity)\n\n### Stars\n\n[**32** stars](/yigitkonur/n8n-docker-ffmpeg/stargazers)\n\n### Watchers\n\n[**1** watching](/yigitkonur/n8n-docker-ffmpeg/watchers)\n\n### Forks\n\n[**31** forks](/yigitkonur/n8n-docker-ffmpeg/forks)\n\n[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Fn8n-docker-ffmpeg&report=yigitkonur+%28user%29)\n\n## [Releases](/yigitkonur/n8n-docker-ffmpeg/releases)\n\nNo releases published\n\n## [Packages 0](/users/yigitkonur/packages?repo_name=n8n-docker-ffmpeg)\n\nNo packages published  \n\n## Languages\n\n-   [Dockerfile 100.0%](/yigitkonur/n8n-docker-ffmpeg/search?l=dockerfile)\n\nYou canâ€™t perform that action at this time.\n\n---\n\n## https://github.com/yigitkonur/fastapi-http-proxy-with-caching\n\nGitHub - yigitkonur/fastapi-http-proxy-with-caching: A FastAPI-based HTTP proxy with request caching using Redis, designed to forward requests while caching responses for efficient repeated queries.                                             \n\n[Skip to content](#start-of-content)   \n\n## Navigation Menu\n\nToggle navigation\n\n[](/)\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Ffastapi-http-proxy-with-caching)\n\nAppearance settings\n\n  \n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n\n# Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\n Include my email address so I can be contacted\n\nCancel Submit feedback\n\n# Saved searches\n\n## Use saved searches to filter your results more quickly\n\nName  \n\nQuery \n\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\n\nCancel Create saved search\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Ffastapi-http-proxy-with-caching)\n\n[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=yigitkonur%2Ffastapi-http-proxy-with-caching)\n\nAppearance settings\n\nResetting focus\n\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\n\n[yigitkonur](/yigitkonur) / **[fastapi-http-proxy-with-caching](/yigitkonur/fastapi-http-proxy-with-caching)** Public\n\n-   [Notifications](/login?return_to=%2Fyigitkonur%2Ffastapi-http-proxy-with-caching) You must be signed in to change notification settings\n-   [Fork 1](/login?return_to=%2Fyigitkonur%2Ffastapi-http-proxy-with-caching)\n-   [Star 10](/login?return_to=%2Fyigitkonur%2Ffastapi-http-proxy-with-caching)\n    \n\nA FastAPI-based HTTP proxy with request caching using Redis, designed to forward requests while caching responses for efficient repeated queries.\n\n[10 stars](/yigitkonur/fastapi-http-proxy-with-caching/stargazers) [1 fork](/yigitkonur/fastapi-http-proxy-with-caching/forks) [Branches](/yigitkonur/fastapi-http-proxy-with-caching/branches) [Tags](/yigitkonur/fastapi-http-proxy-with-caching/tags) [Activity](/yigitkonur/fastapi-http-proxy-with-caching/activity)\n\n[Star](/login?return_to=%2Fyigitkonur%2Ffastapi-http-proxy-with-caching)\n\n[Notifications](/login?return_to=%2Fyigitkonur%2Ffastapi-http-proxy-with-caching) You must be signed in to change notification settings\n\n# yigitkonur/fastapi-http-proxy-with-caching\n\n  \n\nÂ main\n\n[Branches](/yigitkonur/fastapi-http-proxy-with-caching/branches)[Tags](/yigitkonur/fastapi-http-proxy-with-caching/tags)\n\n[](/yigitkonur/fastapi-http-proxy-with-caching/branches)[](/yigitkonur/fastapi-http-proxy-with-caching/tags)\n\nGo to file\n\nCode\n\nOpen more actions menu\n\n## Folders and files\n\nName\n\nName\n\nLast commit message\n\nLast commit date\n\n## Latest commit\n\n## History\n\n[5 Commits](/yigitkonur/fastapi-http-proxy-with-caching/commits/main/)\n\n[](/yigitkonur/fastapi-http-proxy-with-caching/commits/main/)\n\n[app](/yigitkonur/fastapi-http-proxy-with-caching/tree/main/app \"app\")\n\n[app](/yigitkonur/fastapi-http-proxy-with-caching/tree/main/app \"app\")\n\n[.env.example](/yigitkonur/fastapi-http-proxy-with-caching/blob/main/.env.example \".env.example\")\n\n[.env.example](/yigitkonur/fastapi-http-proxy-with-caching/blob/main/.env.example \".env.example\")\n\n[.gitignore](/yigitkonur/fastapi-http-proxy-with-caching/blob/main/.gitignore \".gitignore\")\n\n[.gitignore](/yigitkonur/fastapi-http-proxy-with-caching/blob/main/.gitignore \".gitignore\")\n\n[Dockerfile](/yigitkonur/fastapi-http-proxy-with-caching/blob/main/Dockerfile \"Dockerfile\")\n\n[Dockerfile](/yigitkonur/fastapi-http-proxy-with-caching/blob/main/Dockerfile \"Dockerfile\")\n\n[README.md](/yigitkonur/fastapi-http-proxy-with-caching/blob/main/README.md \"README.md\")\n\n[README.md](/yigitkonur/fastapi-http-proxy-with-caching/blob/main/README.md \"README.md\")\n\n[main.py](/yigitkonur/fastapi-http-proxy-with-caching/blob/main/main.py \"main.py\")\n\n[main.py](/yigitkonur/fastapi-http-proxy-with-caching/blob/main/main.py \"main.py\")\n\n[requirements.txt](/yigitkonur/fastapi-http-proxy-with-caching/blob/main/requirements.txt \"requirements.txt\")\n\n[requirements.txt](/yigitkonur/fastapi-http-proxy-with-caching/blob/main/requirements.txt \"requirements.txt\")\n\nView all files\n\n## Repository files navigation\n\n# ðŸš€ FastAPI Transparent Proxy ðŸš€\n\n[](#-fastapi-transparent-proxy-)\n\n### Stop paying for duplicate API calls. Start caching like a pro.\n\n[](#stop-paying-for-duplicate-api-calls-start-caching-like-a-pro)\n\n**_The ultimate transparent HTTP proxy for no-code platforms. It sits between your automations and expensive APIs, caching responses based on MD5 hashes so identical requests return instantly._**\n\n[![python](https://camo.githubusercontent.com/4808218212ece46251343f2523af0fdfb557a5bef0edc616a82c5480e8cd2da2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e31302b2d3444383745362e7376673f7374796c653d666c61742d737175617265)](#) [![fastapi](https://camo.githubusercontent.com/ee156a544c678f4857fb274b0b51778e314c50fa337186bdd24a90e2c2944220/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f466173744150492d302e3130392b2d3030393638382e7376673f7374796c653d666c61742d737175617265)](#) Â Â â€¢Â Â  [![license](https://camo.githubusercontent.com/b9394454fa0b691582af19a29fc9d773de827bf10e109544bf7b49f16e43032f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d4639413832352e7376673f7374796c653d666c61742d737175617265)](#) [![platform](https://camo.githubusercontent.com/7f42215b2c1c3bcfff02d35ad7de2b7fa485b9259eb48dab60d00d2c4ed72420/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d2d6d61634f535f7c5f4c696e75785f7c5f57696e646f77735f7c5f446f636b65722d3245443537332e7376673f7374796c653d666c61742d737175617265)](#)\n\n[![zero config](https://camo.githubusercontent.com/18476f2f60291c58201bb083d0df13d618ae4896c4bf94d59e6453f40cef1692/68747470733a2f2f696d672e736869656c64732e696f2f62616467652fe29a99efb88f5f7a65726f5f636f6e6669672d776f726b735f776974686f75745f72656469732d3245443537332e7376673f7374796c653d666f722d7468652d6261646765)](https://camo.githubusercontent.com/18476f2f60291c58201bb083d0df13d618ae4896c4bf94d59e6453f40cef1692/68747470733a2f2f696d672e736869656c64732e696f2f62616467652fe29a99efb88f5f7a65726f5f636f6e6669672d776f726b735f776974686f75745f72656469732d3245443537332e7376673f7374796c653d666f722d7468652d6261646765) [![n8n ready](https://camo.githubusercontent.com/79b828b4c4884c45f0b7feb67cd85c1db29afff77a093d2fb7616e05873d0ce4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09f94a75f6e6f2d2d636f64655f72656164792d6e386e5f7c5f4d616b655f7c5f5a61706965722d3245443537332e7376673f7374796c653d666f722d7468652d6261646765)](https://camo.githubusercontent.com/79b828b4c4884c45f0b7feb67cd85c1db29afff77a093d2fb7616e05873d0ce4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09f94a75f6e6f2d2d636f64655f72656164792d6e386e5f7c5f4d616b655f7c5f5a61706965722d3245443537332e7376673f7374796c653d666f722d7468652d6261646765)\n\n### ðŸ§­ Quick Navigation\n\n[](#-quick-navigation)\n\n[**âš¡ Get Started**](#-get-started-in-60-seconds) â€¢ [**âœ¨ Key Features**](#-feature-breakdown-the-secret-sauce) â€¢ [**ðŸŽ® Usage & Examples**](#-usage-fire-and-forget) â€¢ [**âš™ï¸ Configuration**](#%EF%B8%8F-configuration) â€¢ [**ðŸ†š Why This Slaps**](#-why-this-slaps-other-methods)\n\n* * *\n\n**FastAPI Transparent Proxy** is the caching layer your no-code automations wish they had. Stop making the same API calls over and over. This proxy sits between your n8n/Make/Zapier workflows and expensive third-party APIs, returning cached responses for identical requestsâ€”saving bandwidth, reducing latency, and cutting your API bills.\n\n### ðŸ§ \n\n[](#)\n\n**MD5 Deduplication**  \nSame request = same cache key\n\n### âš¡\n\n[](#-1)\n\n**Sub-ms Response**  \nCache hits are instant\n\n### ðŸ”Œ\n\n[](#-2)\n\n**Zero Config**  \nWorks without Redis too\n\nHow it slaps:\n\n-   **You:** Point your n8n HTTP Request node to this proxy\n-   **Proxy:** Hashes the request, checks cache, returns or forwards\n-   **Result:** First call hits the API, next 1000 identical calls return instantly\n-   **Your wallet:** ðŸ“ˆ\n\n* * *\n\n## ðŸ’¥ Why This Slaps Other Methods\n\n[](#-why-this-slaps-other-methods)\n\nManually deduplicating API calls in no-code is a nightmare. This proxy makes other approaches look ancient.\n\n**âŒ The Old Way (Pain)**\n\n**âœ… The Proxy Way (Glory)**\n\n1.  Build complex \"check if already fetched\" logic\n2.  Store results in Airtable/Notion/Sheets\n3.  Add branches: \"if cached then skip\"\n4.  Debug why your workflow is 47 nodes\n5.  Pay for 1000 duplicate API calls anyway\n\n1.  Deploy this proxy (one command)\n2.  Change your API URL to proxy URL\n3.  Done. Caching is automatic.\n4.  Watch your API costs drop 90%\n5.  Go grab a coffee. â˜•\n\nWe're not just forwarding requests. We're building **deterministic cache keys** from MD5 hashes of `method + URL + headers + body`, so identical business requests always hit the same cache entryâ€”even across different workflow runs.\n\n* * *\n\n## ðŸš€ Get Started in 60 Seconds\n\n[](#-get-started-in-60-seconds)\n\nPlatform\n\nOne-liner\n\nðŸ³ **Docker**\n\n`docker run -p 8000:8000 ghcr.io/yigitkonur/fastapi-proxy`\n\nðŸ **Python**\n\n`pip install -r requirements.txt && uvicorn main:app`\n\nâ˜ï¸ **Railway/Render**\n\nDeploy from GitHub, set `REDIS_URL` env var\n\n### Quick Install (Python)\n\n[](#quick-install-python)\n\n# Clone and enter\ngit clone https://github.com/yigitkonur/fastapi-http-proxy-with-caching.git\ncd fastapi-http-proxy-with-caching\n\n# Setup virtual environment\npython3 -m venv venv\nsource venv/bin/activate  # Windows: venv\\\\Scripts\\\\activate\npip install -r requirements.txt\n\n# Run (works immediately, even without Redis!)\nuvicorn main:app --host 0.0.0.0 --port 8000\n\n> **âœ¨ Zero Config:** The proxy starts in **degraded mode** without Redisâ€”requests still work, just without caching. Add Redis when you're ready for the full experience.\n\n* * *\n\n## ðŸŽ® Usage: Fire and Forget\n\n[](#-usage-fire-and-forget)\n\n### Basic Proxy Request\n\n[](#basic-proxy-request)\n\n# Instead of calling the API directly...\ncurl -X POST \"https://expensive-api.com/data\" -d '{\"query\": \"foo\"}'\n\n# Route through the proxy:\ncurl -X POST \"http://localhost:8000/proxy?url=https://expensive-api.com/data\" \\\\\n  -H \"Content-Type: application/json\" \\\\\n  -d '{\"query\": \"foo\"}'\n\n### Response Format\n\n[](#response-format)\n\n{\n  \"success\": true,\n  \"cached\": true,\n  \"cache\\_key\": \"a1b2c3d4e5f67890\",\n  \"status\\_code\": 200,\n  \"data\": { \"your\": \"api response\" }\n}\n\nThe `cached: true` means you just saved an API call. ðŸŽ‰\n\n### In n8n\n\n[](#in-n8n)\n\n1.  Add an **HTTP Request** node\n2.  Set URL to: `http://your-proxy:8000/proxy?url=https://actual-api.com/endpoint`\n3.  Configure method, headers, body as normal\n4.  Every identical request now returns from cache\n\n### Advanced Options\n\n[](#advanced-options)\n\n# Force fresh request (bypass cache)\ncurl \"http://localhost:8000/proxy?url=https://api.com/data&bypass\\_cache=true\"\n\n# Custom cache TTL (2 hours instead of default 1 hour)\ncurl \"http://localhost:8000/proxy?url=https://api.com/data&cache\\_ttl=7200\"\n\n### Health & Admin Endpoints\n\n[](#health--admin-endpoints)\n\n# Health check (great for load balancers)\ncurl http://localhost:8000/health\n# â†’ {\"status\": \"healthy\", \"redis\\_connected\": true, \"version\": \"2.0.0\"}\n\n# Cache statistics\ncurl http://localhost:8000/cache/stats\n# â†’ {\"total\\_keys\": 1547, \"memory\\_usage\": \"2.3M\", \"prefix\": \"proxy:cache:\"}\n\n# Nuclear option: clear all cache\ncurl -X DELETE http://localhost:8000/cache\n# â†’ {\"deleted\": 1547, \"message\": \"Cleared 1547 cached entries\"}\n\n* * *\n\n## âœ¨ Feature Breakdown: The Secret Sauce\n\n[](#-feature-breakdown-the-secret-sauce)\n\nFeature\n\nWhat It Does\n\nWhy You Care\n\n**ðŸ§  MD5 Hashing**  \nDeterministic keys\n\nHashes `method + URL + headers + body` into cache key\n\nIdentical requests always return same cached response\n\n**âš¡ Graceful Degradation**  \nNo Redis? No problem\n\nStarts without Redis, just skips caching\n\nDeploy anywhere, add Redis later\n\n**ðŸ”„ All HTTP Methods**  \nNot just POST\n\nGET, POST, PUT, DELETE, PATCH all supported\n\nWorks with any API pattern\n\n**â° Flexible TTL**  \nPer-request control\n\nDefault 1 hour, override per request\n\nCache static data longer, dynamic shorter\n\n**ðŸŽ¯ Cache Bypass**  \nWhen you need fresh\n\n`bypass_cache=true` skips cache\n\nForce refresh when needed\n\n**ðŸ“Š Health Checks**  \nProduction ready\n\n`/health` endpoint with Redis status\n\nPerfect for k8s liveness probes\n\n**ðŸ”§ Legacy Support**  \nDrop-in replacement\n\n`/webhook-test/post-response` still works\n\nMigrate existing workflows gradually\n\n* * *\n\n## âš™ï¸ Configuration\n\n[](#ï¸-configuration)\n\nAll settings via environment variables. Copy `.env.example` to `.env`:\n\ncp .env.example .env\n\nVariable\n\nDefault\n\nDescription\n\n`REDIS_URL`\n\n`redis://localhost:6379/0`\n\nRedis connection (or Upstash URL)\n\n`CACHE_TTL_SECONDS`\n\n`3600`\n\nDefault cache lifetime (1 hour)\n\n`CACHE_PREFIX`\n\n`proxy:cache:`\n\nRedis key prefix\n\n`PROXY_TIMEOUT_SECONDS`\n\n`30`\n\nTimeout for proxied requests\n\n`DEBUG`\n\n`false`\n\nEnable verbose logging\n\n### Using Upstash (Serverless Redis)\n\n[](#using-upstash-serverless-redis)\n\n[Upstash](https://upstash.com/) is perfect for thisâ€”pay only for what you use:\n\n1.  Create a database at [console.upstash.com](https://console.upstash.com)\n2.  Copy your Redis URL\n3.  Set in `.env`:\n    \n    ```\n    REDIS_URL=redis://default:YOUR_PASSWORD@YOUR_ENDPOINT.upstash.io:6379\n    ```\n    \n\n**Cost**: ~$0.20 per 100K cached requests. If you're making 1M duplicate calls/month, that's **$2 vs whatever you're paying now**.\n\n* * *\n\n## ðŸ—ï¸ Project Structure\n\n[](#ï¸-project-structure)\n\n```\nâ”œâ”€â”€ main.py                 # Entry point (thin wrapper)\nâ”œâ”€â”€ app/\nâ”‚   â”œâ”€â”€ __init__.py        # Package metadata\nâ”‚   â”œâ”€â”€ main.py            # FastAPI app factory + lifespan\nâ”‚   â”œâ”€â”€ config.py          # Pydantic settings from env\nâ”‚   â”œâ”€â”€ models.py          # Request/response schemas\nâ”‚   â”œâ”€â”€ dependencies.py    # Service injection\nâ”‚   â”œâ”€â”€ services/\nâ”‚   â”‚   â”œâ”€â”€ cache.py       # Redis + MD5 hashing logic\nâ”‚   â”‚   â””â”€â”€ proxy.py       # HTTP forwarding logic\nâ”‚   â””â”€â”€ routes/\nâ”‚       â”œâ”€â”€ proxy.py       # /proxy endpoint\nâ”‚       â””â”€â”€ health.py      # /health, /cache/stats\nâ”œâ”€â”€ requirements.txt       # Pinned dependencies\nâ”œâ”€â”€ Dockerfile            # Multi-stage production build\nâ”œâ”€â”€ .env.example          # Configuration template\nâ””â”€â”€ README.md\n```\n\n* * *\n\n## ðŸ³ Deployment\n\n[](#-deployment)\n\n### Docker (Recommended)\n\n[](#docker-recommended)\n\n# Build\ndocker build -t fastapi-proxy .\n\n# Run (without Redis - degraded mode)\ndocker run -p 8000:8000 fastapi-proxy\n\n# Run with Redis\ndocker run -p 8000:8000 -e REDIS\\_URL=redis://host:6379 fastapi-proxy\n\n### Docker Compose (with Redis)\n\n[](#docker-compose-with-redis)\n\nversion: '3.8'\nservices:\n  proxy:\n    build: .\n    ports:\n      - \"8000:8000\"\n    environment:\n      - REDIS\\_URL=redis://redis:6379/0\n    depends\\_on:\n      - redis\n  redis:\n    image: redis:alpine\n    volumes:\n      - redis\\_data:/data\nvolumes:\n  redis\\_data:\n\n### Systemd (Linux Server)\n\n[](#systemd-linux-server)\n\n\\[Unit\\]\nDescription\\=FastAPI Transparent Proxy\nAfter\\=network.target\n\n\\[Service\\]\nUser\\=www-data\nWorkingDirectory\\=/opt/fastapi-proxy\nEnvironment\\=\"PATH=/opt/fastapi-proxy/venv/bin\"\nExecStart\\=/opt/fastapi-proxy/venv/bin/uvicorn main:app --host 0.0.0.0 --port 8000\nRestart\\=always\n\n\\[Install\\]\nWantedBy\\=multi-user.target\n\n* * *\n\n## ðŸ”¥ Common Issues & Quick Fixes\n\n[](#-common-issues--quick-fixes)\n\n**Expand for troubleshooting tips**\n\nProblem\n\nSolution\n\n**\"Redis unavailable\" warning**\n\nExpected without Redis. The proxy still works, just without caching. Add `REDIS_URL` when ready.\n\n**Cache not working**\n\nCheck `redis_connected: true` in `/health`. Verify your `REDIS_URL` is correct.\n\n**Timeout errors**\n\nIncrease `PROXY_TIMEOUT_SECONDS`. Some APIs are slow.\n\n**Cache key collisions**\n\nShouldn't happenâ€”MD5 is deterministic. If you're seeing wrong cached responses, check if you're modifying headers unintentionally.\n\n**High memory usage**\n\nSet `CACHE_TTL_SECONDS` lower, or use `/cache` DELETE endpoint to clear.\n\n* * *\n\n## ðŸ› ï¸ Development\n\n[](#ï¸-development)\n\n# Clone\ngit clone https://github.com/yigitkonur/fastapi-http-proxy-with-caching.git\ncd fastapi-http-proxy-with-caching\n\n# Setup\npython3 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n\n# Run with hot reload\nuvicorn main:app --reload\n\n# Run tests (coming soon)\npytest\n\n* * *\n\n**Built with ðŸ”¥ because paying for duplicate API calls is a soul-crushing waste of money.**\n\nMIT Â© [YiÄŸit Konur](https://github.com/yigitkonur)\n\n## About\n\nA FastAPI-based HTTP proxy with request caching using Redis, designed to forward requests while caching responses for efficient repeated queries.\n\n### Resources\n\n[Readme](#readme-ov-file)\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n[Activity](/yigitkonur/fastapi-http-proxy-with-caching/activity)\n\n### Stars\n\n[**10** stars](/yigitkonur/fastapi-http-proxy-with-caching/stargazers)\n\n### Watchers\n\n[**1** watching](/yigitkonur/fastapi-http-proxy-with-caching/watchers)\n\n### Forks\n\n[**1** fork](/yigitkonur/fastapi-http-proxy-with-caching/forks)\n\n[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Ffastapi-http-proxy-with-caching&report=yigitkonur+%28user%29)\n\n## [Releases](/yigitkonur/fastapi-http-proxy-with-caching/releases)\n\nNo releases published\n\n## [Packages 0](/users/yigitkonur/packages?repo_name=fastapi-http-proxy-with-caching)\n\nNo packages published  \n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n## Languages\n\n-   [Python 97.0%](/yigitkonur/fastapi-http-proxy-with-caching/search?l=python)\n-   [Dockerfile 3.0%](/yigitkonur/fastapi-http-proxy-with-caching/search?l=dockerfile)\n\nYou canâ€™t perform that action at this time.\n\n---\n\n## https://github.com/yigitkonur/data-preparation-for-fine-tuning\n\nGitHub - yigitkonur/data-preparation-for-fine-tuning: A Python project for preparing and analyzing datasets from JSONL files. It includes tools for shuffling, categorizing, and generating reports on dataset content.                                             \n\n[Skip to content](#start-of-content)   \n\n## Navigation Menu\n\nToggle navigation\n\n[](/)\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Fdata-preparation-for-fine-tuning)\n\nAppearance settings\n\n  \n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n\n# Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\n Include my email address so I can be contacted\n\nCancel Submit feedback\n\n# Saved searches\n\n## Use saved searches to filter your results more quickly\n\nName  \n\nQuery \n\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\n\nCancel Create saved search\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Fdata-preparation-for-fine-tuning)\n\n[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=yigitkonur%2Fdata-preparation-for-fine-tuning)\n\nAppearance settings\n\nResetting focus\n\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\n\n[yigitkonur](/yigitkonur) / **[data-preparation-for-fine-tuning](/yigitkonur/data-preparation-for-fine-tuning)** Public\n\n-   [Notifications](/login?return_to=%2Fyigitkonur%2Fdata-preparation-for-fine-tuning) You must be signed in to change notification settings\n-   [Fork 2](/login?return_to=%2Fyigitkonur%2Fdata-preparation-for-fine-tuning)\n-   [Star 16](/login?return_to=%2Fyigitkonur%2Fdata-preparation-for-fine-tuning)\n    \n\nA Python project for preparing and analyzing datasets from JSONL files. It includes tools for shuffling, categorizing, and generating reports on dataset content.\n\n[16 stars](/yigitkonur/data-preparation-for-fine-tuning/stargazers) [2 forks](/yigitkonur/data-preparation-for-fine-tuning/forks) [Branches](/yigitkonur/data-preparation-for-fine-tuning/branches) [Tags](/yigitkonur/data-preparation-for-fine-tuning/tags) [Activity](/yigitkonur/data-preparation-for-fine-tuning/activity)\n\n[Star](/login?return_to=%2Fyigitkonur%2Fdata-preparation-for-fine-tuning)\n\n[Notifications](/login?return_to=%2Fyigitkonur%2Fdata-preparation-for-fine-tuning) You must be signed in to change notification settings\n\n# yigitkonur/data-preparation-for-fine-tuning\n\n  \n\nÂ main\n\n[Branches](/yigitkonur/data-preparation-for-fine-tuning/branches)[Tags](/yigitkonur/data-preparation-for-fine-tuning/tags)\n\n[](/yigitkonur/data-preparation-for-fine-tuning/branches)[](/yigitkonur/data-preparation-for-fine-tuning/tags)\n\nGo to file\n\nCode\n\nOpen more actions menu\n\n## Folders and files\n\nName\n\nName\n\nLast commit message\n\nLast commit date\n\n## Latest commit\n\n## History\n\n[6 Commits](/yigitkonur/data-preparation-for-fine-tuning/commits/main/)\n\n[](/yigitkonur/data-preparation-for-fine-tuning/commits/main/)\n\n[README.md](/yigitkonur/data-preparation-for-fine-tuning/blob/main/README.md \"README.md\")\n\n[README.md](/yigitkonur/data-preparation-for-fine-tuning/blob/main/README.md \"README.md\")\n\n[config.ini](/yigitkonur/data-preparation-for-fine-tuning/blob/main/config.ini \"config.ini\")\n\n[config.ini](/yigitkonur/data-preparation-for-fine-tuning/blob/main/config.ini \"config.ini\")\n\n[dataset-chooser.py](/yigitkonur/data-preparation-for-fine-tuning/blob/main/dataset-chooser.py \"dataset-chooser.py\")\n\n[dataset-chooser.py](/yigitkonur/data-preparation-for-fine-tuning/blob/main/dataset-chooser.py \"dataset-chooser.py\")\n\n[dataset-evaluator.py](/yigitkonur/data-preparation-for-fine-tuning/blob/main/dataset-evaluator.py \"dataset-evaluator.py\")\n\n[dataset-evaluator.py](/yigitkonur/data-preparation-for-fine-tuning/blob/main/dataset-evaluator.py \"dataset-evaluator.py\")\n\nView all files\n\n## Repository files navigation\n\n#### Introduction\n\n[](#introduction)\n\nWelcome to the `data-preparation-for-fine-tuning` project, a robust and versatile Python toolkit designed for the meticulous preparation and comprehensive analysis of datasets from JSONL files. Our tools, `dataset-chooser.py` and `dataset-evaluator.py`, are not just scripts but powerful instruments in your data science arsenal. They enable users to homogenize datasets based on pre-specified weights for each category, particularly focusing on assistant responses. This feature is especially beneficial for fine-tuning machine learning models, ensuring the dataset aligns perfectly with your specific needs and biases are minimized.\n\n#### JSONL File Format\n\n[](#jsonl-file-format)\n\nOur scripts work with datasets in JSONL format. Each line in a JSONL file is a valid JSON object. Here's a glimpse of what our dataset might look like:\n\n{\"messages\": \\[{\"role\": \"system\", \"content\": \"Classify...\"}, {\"role\": \"user\", \"content\": \"saas...\"}, {\"role\": \"assistant\", \"content\": \"History\"}\\]}\n{\"messages\": \\[{\"role\": \"system\", \"content\": \"Classify...\"}, {\"role\": \"user\", \"content\": \"diskussionsrunden...\"}, {\"role\": \"assistant\", \"content\": \"Retail\"}\\]}\n{\"messages\": \\[{\"role\": \"system\", \"content\": \"Classify...\"}, {\"role\": \"user\", \"content\": \"polis...\"}, {\"role\": \"assistant\", \"content\": \"Consumer Electronics\"}\\]}\n\n#### Installation and Setup\n\n[](#installation-and-setup)\n\n1.  **Clone the Repository:**\n    \n    ```\n    git clone https://github.com/yourusername/data-preparation-for-fine-tuning.git\n    cd data-preparation-for-fine-tuning\n    ```\n    \n2.  **Dependencies:** Python 3.6+ is required. Install dependencies using:\n    \n    ```\n    pip install pandas rich configparser\n    ```\n    \n\n#### Configuration\n\n[](#configuration)\n\n1.  **config.ini File:** Create this in the root directory. Modify paths and weights to suit your dataset:\n    \n    \\[Paths\\]\n    jsonl\\_directory = /path/to/jsonl/files\n    output\\_file = /path/to/output/dataset.jsonl\n    \n    \\[Weights\\]\n    category\\_weights = {\n        \"Category1\": 0.05,\n        ...\n    }\n    \n    \\[Settings\\]\n    total\\_examples = 1000000\n    \n\n#### Usage\n\n[](#usage)\n\n1.  **Dataset Preparation (`dataset-chooser.py`):** Reads, shuffles, and categorizes JSONL files. Tailor your dataset for specific modeling needs.\n    \n    ```\n    python dataset-chooser.py\n    ```\n    \n2.  **Dataset Analysis (`dataset-evaluator.py`):** Analyzes the prepared dataset, providing insightful metrics and distributions.\n    \n    ```\n    python dataset-evaluator.py\n    ```\n    \n\n[![CleanShot 2024-01-01 at 17 52 05@2x](https://private-user-images.githubusercontent.com/9989650/293600727-ee8bb83e-1ef1-4fb7-a167-ba9098406da6.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjQ0NTQ3ODgsIm5iZiI6MTc2NDQ1NDQ4OCwicGF0aCI6Ii85OTg5NjUwLzI5MzYwMDcyNy1lZThiYjgzZS0xZWYxLTRmYjctYTE2Ny1iYTkwOTg0MDZkYTYucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTEyOSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTExMjlUMjIxNDQ4WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YjkyZjc5M2ZlOGU3MTMwMGYxZTQ2ZDI5MWRhOTFjMzY5OTJlMmY5NGY4ZjBkMjE5NDBlMWViNDcyZDEzNTRkYyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.WlFKnLJs_6xaCqd37eliGvCCbz0zc-cuNluxL_5rDNA)](https://private-user-images.githubusercontent.com/9989650/293600727-ee8bb83e-1ef1-4fb7-a167-ba9098406da6.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjQ0NTQ3ODgsIm5iZiI6MTc2NDQ1NDQ4OCwicGF0aCI6Ii85OTg5NjUwLzI5MzYwMDcyNy1lZThiYjgzZS0xZWYxLTRmYjctYTE2Ny1iYTkwOTg0MDZkYTYucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTEyOSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTExMjlUMjIxNDQ4WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YjkyZjc5M2ZlOGU3MTMwMGYxZTQ2ZDI5MWRhOTFjMzY5OTJlMmY5NGY4ZjBkMjE5NDBlMWViNDcyZDEzNTRkYyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.WlFKnLJs_6xaCqd37eliGvCCbz0zc-cuNluxL_5rDNA)\n\n#### Use Cases\n\n[](#use-cases)\n\n-   **Model Training:** Prepare balanced or weighted datasets for training machine learning models, ensuring diverse representation across categories.\n-   **Data Analysis:** Gain insights into the composition of your datasets, identifying prevalent themes or gaps in data.\n-   **Custom Dataset Creation:** Generate datasets tailored to specific research or business needs, focusing on relevant categories.\n\n#### Fine-Tuning Models with Homogenized Data\n\n[](#fine-tuning-models-with-homogenized-data)\n\nUtilizing `data-preparation-for-fine-tuning`, you can fine-tune machine learning models with data that's been carefully balanced or weighted according to your specifications. This process involves:\n\n1.  Defining category weights in `config.ini` to reflect the desired emphasis in your dataset.\n2.  Running `dataset-chooser.py` to prepare a dataset that adheres to these weights.\n3.  Using the processed dataset to train models, ensuring the data is representative and aligned with your goals.\n\nThis approach is particularly useful in scenarios where certain categories need more representation or when trying to avoid biases inherent in unbalanced datasets.\n\n## About\n\nA Python project for preparing and analyzing datasets from JSONL files. It includes tools for shuffling, categorizing, and generating reports on dataset content.\n\n### Resources\n\n[Readme](#readme-ov-file)\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n[Activity](/yigitkonur/data-preparation-for-fine-tuning/activity)\n\n### Stars\n\n[**16** stars](/yigitkonur/data-preparation-for-fine-tuning/stargazers)\n\n### Watchers\n\n[**2** watching](/yigitkonur/data-preparation-for-fine-tuning/watchers)\n\n### Forks\n\n[**2** forks](/yigitkonur/data-preparation-for-fine-tuning/forks)\n\n[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Fdata-preparation-for-fine-tuning&report=yigitkonur+%28user%29)\n\n## [Releases](/yigitkonur/data-preparation-for-fine-tuning/releases)\n\nNo releases published\n\n## [Packages 0](/users/yigitkonur/packages?repo_name=data-preparation-for-fine-tuning)\n\nNo packages published  \n\n## Languages\n\n-   [Python 100.0%](/yigitkonur/data-preparation-for-fine-tuning/search?l=python)\n\nYou canâ€™t perform that action at this time.\n\n---\n\n## https://github.com/yigitkonur/GoogleSheets-Translator\n\nGitHub - yigitkonur/GoogleSheets-Translator: Automate translations in Google Sheets using Google Translate, optimized for handling large datasets with efficient batch processing (by using =GOOGLETRANSLATE formula to handle large amount of data effectively)                                             \n\n[Skip to content](#start-of-content)   \n\n## Navigation Menu\n\nToggle navigation\n\n[](/)\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2FGoogleSheets-Translator)\n\nAppearance settings\n\n  \n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n\n# Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\n Include my email address so I can be contacted\n\nCancel Submit feedback\n\n# Saved searches\n\n## Use saved searches to filter your results more quickly\n\nName  \n\nQuery \n\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\n\nCancel Create saved search\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2FGoogleSheets-Translator)\n\n[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=yigitkonur%2FGoogleSheets-Translator)\n\nAppearance settings\n\nResetting focus\n\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\n\n[yigitkonur](/yigitkonur) / **[GoogleSheets-Translator](/yigitkonur/GoogleSheets-Translator)** Public\n\n-   [Notifications](/login?return_to=%2Fyigitkonur%2FGoogleSheets-Translator) You must be signed in to change notification settings\n-   [Fork 0](/login?return_to=%2Fyigitkonur%2FGoogleSheets-Translator)\n-   [Star 1](/login?return_to=%2Fyigitkonur%2FGoogleSheets-Translator)\n    \n\nAutomate translations in Google Sheets using Google Translate, optimized for handling large datasets with efficient batch processing (by using =GOOGLETRANSLATE formula to handle large amount of data effectively)\n\n[1 star](/yigitkonur/GoogleSheets-Translator/stargazers) [0 forks](/yigitkonur/GoogleSheets-Translator/forks) [Branches](/yigitkonur/GoogleSheets-Translator/branches) [Tags](/yigitkonur/GoogleSheets-Translator/tags) [Activity](/yigitkonur/GoogleSheets-Translator/activity)\n\n[Star](/login?return_to=%2Fyigitkonur%2FGoogleSheets-Translator)\n\n[Notifications](/login?return_to=%2Fyigitkonur%2FGoogleSheets-Translator) You must be signed in to change notification settings\n\n# yigitkonur/GoogleSheets-Translator\n\n  \n\nÂ main\n\n[Branches](/yigitkonur/GoogleSheets-Translator/branches)[Tags](/yigitkonur/GoogleSheets-Translator/tags)\n\n[](/yigitkonur/GoogleSheets-Translator/branches)[](/yigitkonur/GoogleSheets-Translator/tags)\n\nGo to file\n\nCode\n\nOpen more actions menu\n\n## Folders and files\n\nName\n\nName\n\nLast commit message\n\nLast commit date\n\n## Latest commit\n\n## History\n\n[4 Commits](/yigitkonur/GoogleSheets-Translator/commits/main/)\n\n[](/yigitkonur/GoogleSheets-Translator/commits/main/)\n\n[README.md](/yigitkonur/GoogleSheets-Translator/blob/main/README.md \"README.md\")\n\n[README.md](/yigitkonur/GoogleSheets-Translator/blob/main/README.md \"README.md\")\n\n[Translator.gs](/yigitkonur/GoogleSheets-Translator/blob/main/Translator.gs \"Translator.gs\")\n\n[Translator.gs](/yigitkonur/GoogleSheets-Translator/blob/main/Translator.gs \"Translator.gs\")\n\n[new-version.gs](/yigitkonur/GoogleSheets-Translator/blob/main/new-version.gs \"new-version.gs\")\n\n[new-version.gs](/yigitkonur/GoogleSheets-Translator/blob/main/new-version.gs \"new-version.gs\")\n\nView all files\n\n## Repository files navigation\n\n# GoogleSheets-Translator\n\n[](#googlesheets-translator)\n\nAutomate translations in Google Sheets using the Google Translate formula. This script is designed to efficiently handle large datasets, processing translations in batches and updating the sheet with minimal delay.\n\n## Features\n\n[](#features)\n\n-   **Batch Translation**: Processes translations in manageable chunks to avoid spreadsheet performance issues.\n-   **Customizable**: Easily configurable for different source/target languages and columns.\n-   **User-Friendly**: Provides a simple menu in Google Sheets for easy access to the translation functionality.\n-   **Resumable**: Picks up where it left off, making it suitable for very large datasets.\n\n## Setup\n\n[](#setup)\n\n1.  **Open Your Google Sheet**: The sheet where you want to perform translations.\n2.  **Access Apps Script**: Go to `Extensions` > `Apps Script` in the Google Sheets menu.\n3.  **Create a New Script**: Replace any existing code with the contents of `Translator.gs`.\n4.  **Save and Close**: After pasting the code, save the project and close the script editor.\n5.  **Reload the Sheet**: Refresh your Google Sheets tab to see the new 'Translation Tools' menu.\n\n## Usage\n\n[](#usage)\n\n-   Click on the `Translation Tools` menu in your Google Sheet.\n-   Select `Translate Text` to start the translation process.\n-   The script will process translations in batches (default 500 rows at a time).\n-   You can rerun the script from the menu to process additional batches.\n\n## Configuration\n\n[](#configuration)\n\nEdit the `translateText` function in `Translator.gs` to change the configuration:\n\nconst config \\= {\n  sourceColumn: 'E',        // Column containing the original text\n  targetColumn: 'F',        // Column where the translated text will be placed\n  sourceLanguage: 'en',     // Source language (e.g., 'en' for English)\n  targetLanguage: 'pt',     // Target language (e.g., 'pt' for Portuguese)\n  chunkSize: 500,           // Number of rows processed in each batch\n  maxRow: 36774             // Maximum row to process\n};\n\n## About\n\nAutomate translations in Google Sheets using Google Translate, optimized for handling large datasets with efficient batch processing (by using =GOOGLETRANSLATE formula to handle large amount of data effectively)\n\n### Resources\n\n[Readme](#readme-ov-file)\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n[Activity](/yigitkonur/GoogleSheets-Translator/activity)\n\n### Stars\n\n[**1** star](/yigitkonur/GoogleSheets-Translator/stargazers)\n\n### Watchers\n\n[**1** watching](/yigitkonur/GoogleSheets-Translator/watchers)\n\n### Forks\n\n[**0** forks](/yigitkonur/GoogleSheets-Translator/forks)\n\n[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fyigitkonur%2FGoogleSheets-Translator&report=yigitkonur+%28user%29)\n\n## [Releases](/yigitkonur/GoogleSheets-Translator/releases)\n\nNo releases published\n\n## [Packages 0](/users/yigitkonur/packages?repo_name=GoogleSheets-Translator)\n\nNo packages published  \n\n## Languages\n\n-   [JavaScript 100.0%](/yigitkonur/GoogleSheets-Translator/search?l=javascript)\n\nYou canâ€™t perform that action at this time.\n\n---\n\n## https://github.com/yigitkonur/Go-JSON-AzureSearch-Prepper\n\nGitHub - yigitkonur/Go-JSON-AzureSearch-Prepper: A Go utility for processing and combining JSON files, making them ready for integration with Azure Search AI.                                             \n\n[Skip to content](#start-of-content)   \n\n## Navigation Menu\n\nToggle navigation\n\n[](/)\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2FGo-JSON-AzureSearch-Prepper)\n\nAppearance settings\n\n  \n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n\n# Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\n Include my email address so I can be contacted\n\nCancel Submit feedback\n\n# Saved searches\n\n## Use saved searches to filter your results more quickly\n\nName  \n\nQuery \n\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\n\nCancel Create saved search\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2FGo-JSON-AzureSearch-Prepper)\n\n[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=yigitkonur%2FGo-JSON-AzureSearch-Prepper)\n\nAppearance settings\n\nResetting focus\n\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\n\n[yigitkonur](/yigitkonur) / **[Go-JSON-AzureSearch-Prepper](/yigitkonur/Go-JSON-AzureSearch-Prepper)** Public\n\n-   [Notifications](/login?return_to=%2Fyigitkonur%2FGo-JSON-AzureSearch-Prepper) You must be signed in to change notification settings\n-   [Fork 0](/login?return_to=%2Fyigitkonur%2FGo-JSON-AzureSearch-Prepper)\n-   [Star 2](/login?return_to=%2Fyigitkonur%2FGo-JSON-AzureSearch-Prepper)\n    \n\nA Go utility for processing and combining JSON files, making them ready for integration with Azure Search AI.\n\n[2 stars](/yigitkonur/Go-JSON-AzureSearch-Prepper/stargazers) [0 forks](/yigitkonur/Go-JSON-AzureSearch-Prepper/forks) [Branches](/yigitkonur/Go-JSON-AzureSearch-Prepper/branches) [Tags](/yigitkonur/Go-JSON-AzureSearch-Prepper/tags) [Activity](/yigitkonur/Go-JSON-AzureSearch-Prepper/activity)\n\n[Star](/login?return_to=%2Fyigitkonur%2FGo-JSON-AzureSearch-Prepper)\n\n[Notifications](/login?return_to=%2Fyigitkonur%2FGo-JSON-AzureSearch-Prepper) You must be signed in to change notification settings\n\n# yigitkonur/Go-JSON-AzureSearch-Prepper\n\n  \n\nÂ main\n\n[Branches](/yigitkonur/Go-JSON-AzureSearch-Prepper/branches)[Tags](/yigitkonur/Go-JSON-AzureSearch-Prepper/tags)\n\n[](/yigitkonur/Go-JSON-AzureSearch-Prepper/branches)[](/yigitkonur/Go-JSON-AzureSearch-Prepper/tags)\n\nGo to file\n\nCode\n\nOpen more actions menu\n\n## Folders and files\n\nName\n\nName\n\nLast commit message\n\nLast commit date\n\n## Latest commit\n\n## History\n\n[6 Commits](/yigitkonur/Go-JSON-AzureSearch-Prepper/commits/main/)\n\n[](/yigitkonur/Go-JSON-AzureSearch-Prepper/commits/main/)\n\n[README.md](/yigitkonur/Go-JSON-AzureSearch-Prepper/blob/main/README.md \"README.md\")\n\n[README.md](/yigitkonur/Go-JSON-AzureSearch-Prepper/blob/main/README.md \"README.md\")\n\n[main.go](/yigitkonur/Go-JSON-AzureSearch-Prepper/blob/main/main.go \"main.go\")\n\n[main.go](/yigitkonur/Go-JSON-AzureSearch-Prepper/blob/main/main.go \"main.go\")\n\n[processor.go](/yigitkonur/Go-JSON-AzureSearch-Prepper/blob/main/processor.go \"processor.go\")\n\n[processor.go](/yigitkonur/Go-JSON-AzureSearch-Prepper/blob/main/processor.go \"processor.go\")\n\n[types.go](/yigitkonur/Go-JSON-AzureSearch-Prepper/blob/main/types.go \"types.go\")\n\n[types.go](/yigitkonur/Go-JSON-AzureSearch-Prepper/blob/main/types.go \"types.go\")\n\nView all files\n\n## Repository files navigation\n\n# Go-JSON-AzureSearch-Prepper\n\n[](#go-json-azuresearch-prepper)\n\nA robust and efficient Go utility for processing large volumes of JSON files, preparing them for Azure Search AI. This tool handles concurrent processing of multiple JSON files, compiles them into a singular JSON and CSV format, and assigns unique identifiers to each entry, making the data ready for further use in Azure Search AI.\n\n## Features\n\n[](#features)\n\n-   **Concurrent JSON File Processing**: Optimized for handling large datasets with speed and efficiency.\n-   **Unique Identifier Assignment**: Each JSON entry is assigned a unique identifier, ensuring data integrity.\n-   **Customizable Output**: Generates both JSON and CSV outputs, suitable for various use cases including Azure Search AI.\n-   **Progress Tracking**: Includes a progress bar for real-time processing updates.\n-   **Modular Design**: Easily extendable for additional data processing needs.\n\n## Use Cases\n\n[](#use-cases)\n\n-   **Azure Search AI Preparation**: Prepare and aggregate data from multiple JSON files for Azure Search AI.\n-   **Data Transformation**: Transform JSON data into a structured CSV format for analytics and reporting.\n-   **Data Integration**: Integrate and consolidate disparate JSON data sources for unified processing and analysis.\n\n## Getting Started\n\n[](#getting-started)\n\n### Prerequisites\n\n[](#prerequisites)\n\n-   Go (version 1.16 or later)\n-   Basic understanding of Go project structure and modules\n\n### Installation\n\n[](#installation)\n\n1.  Clone the repository:\n    \n    git clone https://github.com/yourusername/Go-JSON-AzureSearch-Prepper.git\n    \n2.  Navigate to the project directory:\n    \n    cd Go-JSON-AzureSearch-Prepper\n    \n3.  Install dependencies:\n    \n    go get -v ./...\n    \n\n### Usage\n\n[](#usage)\n\n1.  Update the `processorConfig` in `main.go` with the paths to your input JSON files, output JSON file, and output CSV file.\n2.  Run the program:\n    \n    go run main.go\n    \n\n## About\n\nA Go utility for processing and combining JSON files, making them ready for integration with Azure Search AI.\n\n### Resources\n\n[Readme](#readme-ov-file)\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n[Activity](/yigitkonur/Go-JSON-AzureSearch-Prepper/activity)\n\n### Stars\n\n[**2** stars](/yigitkonur/Go-JSON-AzureSearch-Prepper/stargazers)\n\n### Watchers\n\n[**1** watching](/yigitkonur/Go-JSON-AzureSearch-Prepper/watchers)\n\n### Forks\n\n[**0** forks](/yigitkonur/Go-JSON-AzureSearch-Prepper/forks)\n\n[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fyigitkonur%2FGo-JSON-AzureSearch-Prepper&report=yigitkonur+%28user%29)\n\n## [Releases](/yigitkonur/Go-JSON-AzureSearch-Prepper/releases)\n\nNo releases published\n\n## [Packages 0](/users/yigitkonur/packages?repo_name=Go-JSON-AzureSearch-Prepper)\n\nNo packages published  \n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n## Languages\n\n-   [Go 100.0%](/yigitkonur/Go-JSON-AzureSearch-Prepper/search?l=go)\n\nYou canâ€™t perform that action at this time.\n\n---\n\n## https://github.com/yigitkonur/bulk-openai-embeddings-creator\n\nGitHub - yigitkonur/bulk-openai-embeddings-creator: A multi-threaded script & CLI tool for generating embeddings from text using multiple OpenAI endpoints. Supports resuming from previously processed data and customizable thread configurations                                             \n\n[Skip to content](#start-of-content)   \n\n## Navigation Menu\n\nToggle navigation\n\n[](/)\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Fbulk-openai-embeddings-creator)\n\nAppearance settings\n\n  \n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n\n# Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\n Include my email address so I can be contacted\n\nCancel Submit feedback\n\n# Saved searches\n\n## Use saved searches to filter your results more quickly\n\nName  \n\nQuery \n\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\n\nCancel Create saved search\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Fbulk-openai-embeddings-creator)\n\n[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=yigitkonur%2Fbulk-openai-embeddings-creator)\n\nAppearance settings\n\nResetting focus\n\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\n\n[yigitkonur](/yigitkonur) / **[bulk-openai-embeddings-creator](/yigitkonur/bulk-openai-embeddings-creator)** Public\n\n-   [Notifications](/login?return_to=%2Fyigitkonur%2Fbulk-openai-embeddings-creator) You must be signed in to change notification settings\n-   [Fork 1](/login?return_to=%2Fyigitkonur%2Fbulk-openai-embeddings-creator)\n-   [Star 8](/login?return_to=%2Fyigitkonur%2Fbulk-openai-embeddings-creator)\n    \n\nA multi-threaded script & CLI tool for generating embeddings from text using multiple OpenAI endpoints. Supports resuming from previously processed data and customizable thread configurations\n\n[8 stars](/yigitkonur/bulk-openai-embeddings-creator/stargazers) [1 fork](/yigitkonur/bulk-openai-embeddings-creator/forks) [Branches](/yigitkonur/bulk-openai-embeddings-creator/branches) [Tags](/yigitkonur/bulk-openai-embeddings-creator/tags) [Activity](/yigitkonur/bulk-openai-embeddings-creator/activity)\n\n[Star](/login?return_to=%2Fyigitkonur%2Fbulk-openai-embeddings-creator)\n\n[Notifications](/login?return_to=%2Fyigitkonur%2Fbulk-openai-embeddings-creator) You must be signed in to change notification settings\n\n# yigitkonur/bulk-openai-embeddings-creator\n\n  \n\nÂ main\n\n[Branches](/yigitkonur/bulk-openai-embeddings-creator/branches)[Tags](/yigitkonur/bulk-openai-embeddings-creator/tags)\n\n[](/yigitkonur/bulk-openai-embeddings-creator/branches)[](/yigitkonur/bulk-openai-embeddings-creator/tags)\n\nGo to file\n\nCode\n\nOpen more actions menu\n\n## Folders and files\n\nName\n\nName\n\nLast commit message\n\nLast commit date\n\n## Latest commit\n\n## History\n\n[7 Commits](/yigitkonur/bulk-openai-embeddings-creator/commits/main/)\n\n[](/yigitkonur/bulk-openai-embeddings-creator/commits/main/)\n\n[README.md](/yigitkonur/bulk-openai-embeddings-creator/blob/main/README.md \"README.md\")\n\n[README.md](/yigitkonur/bulk-openai-embeddings-creator/blob/main/README.md \"README.md\")\n\n[pinecone-pusher.py](/yigitkonur/bulk-openai-embeddings-creator/blob/main/pinecone-pusher.py \"pinecone-pusher.py\")\n\n[pinecone-pusher.py](/yigitkonur/bulk-openai-embeddings-creator/blob/main/pinecone-pusher.py \"pinecone-pusher.py\")\n\n[run.py](/yigitkonur/bulk-openai-embeddings-creator/blob/main/run.py \"run.py\")\n\n[run.py](/yigitkonur/bulk-openai-embeddings-creator/blob/main/run.py \"run.py\")\n\n[test.py](/yigitkonur/bulk-openai-embeddings-creator/blob/main/test.py \"test.py\")\n\n[test.py](/yigitkonur/bulk-openai-embeddings-creator/blob/main/test.py \"test.py\")\n\nView all files\n\n## Repository files navigation\n\n# Multi-threaded OpenAI Embedding Vector Generator\n\n[](#multi-threaded-openai-embedding-vector-generator)\n\nThis script generates embeddings from text using multiple OpenAI endpoints. It supports multi-threading and can resume from previously processed data. It reads data from Excel, CSV, or JSON files and writes output to TSV, CSV, or JSON files.\n\n## Requirements\n\n[](#requirements)\n\n-   Python 3\n-   pandas\n-   requests\n-   openai\n-   tqdm\n\nYou can install the necessary libraries using pip:\n\npip install pandas requests openai tqdm\n\n## Usage\n\n[](#usage)\n\nYou can run the script from the command line with the following arguments:\n\n-   `--input`: Path to the input file (Excel, CSV, or JSON format).\n-   `--output`: Path to the output file (TSV, CSV, or JSON format).\n-   `--config`: Path to the configuration file (JSON format).\n-   `--threads`: Number of worker threads (default is 50).\n-   `--batch-size`: Number of items to process before saving results (default is 100).\n-   `--retry-limit`: Number of times to retry on error (default is 5).\n\nHere's an example of how to run the script:\n\npython run.py --input input.xlsx --output output.tsv --config config.json --threads 100 --batch-size 200 --retry-limit 3\n\n## Configuration File\n\n[](#configuration-file)\n\nThe configuration file is a JSON file that contains the OpenAI endpoints and keys. It is useful when you need to setup multiple regions to avoid rate limit for millions of docs to get embed.\n\nHere's an example of what the configuration file might look like:\n\n{\n  \"openai\\_endpoints\\_and\\_keys\": \\[\n    \\[\"https://xxx.openai.azure.com\", \"api\\_key\\_1\", \"embed\"\\],\n    \\[\"https://xxx.openai.azure.com\", \"api\\_key\\_2\", \"embed\"\\],\n    \\[\"https://xxx.openai.azure.com\", \"api\\_key\\_3\", \"embed\"\\],\n    \\[\"https://xxx.openai.azure.com\", \"api\\_key\\_4\", \"embed\"\\]\n  \\]\n}\n\n## Input File\n\n[](#input-file)\n\nThe input file should be an Excel, CSV, or JSON file containing the text from which to generate embeddings. The script will dynamically handle the columns present in the input file.\n\n## Output File\n\n[](#output-file)\n\nThe output file will be a TSV, CSV, or JSON file containing the generated embeddings along with the original data. The script will create an additional `vectors` column for the embeddings.\n\n## Progress\n\n[](#progress)\n\nThe script displays a progress bar while processing the documents. It also logs information about the processing status and any errors that occur.\n\n[![CleanShot 2023-10-04 at 11 01 12](https://private-user-images.githubusercontent.com/9989650/272537920-6e0baadd-de70-45b1-af44-928a1a72e261.gif?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjQ0NTQ3OTMsIm5iZiI6MTc2NDQ1NDQ5MywicGF0aCI6Ii85OTg5NjUwLzI3MjUzNzkyMC02ZTBiYWFkZC1kZTcwLTQ1YjEtYWY0NC05MjhhMWE3MmUyNjEuZ2lmP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTEyOSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTExMjlUMjIxNDUzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MDJmMjcwNTQxZGQ0ZWIwYjE3N2I0NGJkZjNlMmVjMjk0MTBkZmJjYmQ0YTFkMmIyZmIwYzQwNTE5YjRiNjU0YSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.fQV4jNP4CgsSzvyRiC4IGKRdL2W35F06podbBsHMFMg)](https://private-user-images.githubusercontent.com/9989650/272537920-6e0baadd-de70-45b1-af44-928a1a72e261.gif?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjQ0NTQ3OTMsIm5iZiI6MTc2NDQ1NDQ5MywicGF0aCI6Ii85OTg5NjUwLzI3MjUzNzkyMC02ZTBiYWFkZC1kZTcwLTQ1YjEtYWY0NC05MjhhMWE3MmUyNjEuZ2lmP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTEyOSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTExMjlUMjIxNDUzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MDJmMjcwNTQxZGQ0ZWIwYjE3N2I0NGJkZjNlMmVjMjk0MTBkZmJjYmQ0YTFkMmIyZmIwYzQwNTE5YjRiNjU0YSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.fQV4jNP4CgsSzvyRiC4IGKRdL2W35F06podbBsHMFMg)\n\n## About\n\nA multi-threaded script & CLI tool for generating embeddings from text using multiple OpenAI endpoints. Supports resuming from previously processed data and customizable thread configurations\n\n### Resources\n\n[Readme](#readme-ov-file)\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n[Activity](/yigitkonur/bulk-openai-embeddings-creator/activity)\n\n### Stars\n\n[**8** stars](/yigitkonur/bulk-openai-embeddings-creator/stargazers)\n\n### Watchers\n\n[**1** watching](/yigitkonur/bulk-openai-embeddings-creator/watchers)\n\n### Forks\n\n[**1** fork](/yigitkonur/bulk-openai-embeddings-creator/forks)\n\n[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Fbulk-openai-embeddings-creator&report=yigitkonur+%28user%29)\n\n## [Releases](/yigitkonur/bulk-openai-embeddings-creator/releases)\n\nNo releases published\n\n## [Packages 0](/users/yigitkonur/packages?repo_name=bulk-openai-embeddings-creator)\n\nNo packages published  \n\n## Languages\n\n-   [Python 100.0%](/yigitkonur/bulk-openai-embeddings-creator/search?l=python)\n\nYou canâ€™t perform that action at this time.\n\n---\n\n## https://github.com/yigitkonur/pineconedb-appscript-integration-for-sheets\n\nGitHub - yigitkonur/pineconedb-appscript-integration-for-sheets: A Google Apps Script custom function to fetch similar categories from a vector database using OpenAI and Pinecone APIs. This function can be used directly in Google Sheets.                                             \n\n[Skip to content](#start-of-content)   \n\n## Navigation Menu\n\nToggle navigation\n\n[](/)\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Fpineconedb-appscript-integration-for-sheets)\n\nAppearance settings\n\n  \n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n\n# Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\n Include my email address so I can be contacted\n\nCancel Submit feedback\n\n# Saved searches\n\n## Use saved searches to filter your results more quickly\n\nName  \n\nQuery \n\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\n\nCancel Create saved search\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Fpineconedb-appscript-integration-for-sheets)\n\n[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=yigitkonur%2Fpineconedb-appscript-integration-for-sheets)\n\nAppearance settings\n\nResetting focus\n\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\n\n[yigitkonur](/yigitkonur) / **[pineconedb-appscript-integration-for-sheets](/yigitkonur/pineconedb-appscript-integration-for-sheets)** Public\n\n-   [Notifications](/login?return_to=%2Fyigitkonur%2Fpineconedb-appscript-integration-for-sheets) You must be signed in to change notification settings\n-   [Fork 0](/login?return_to=%2Fyigitkonur%2Fpineconedb-appscript-integration-for-sheets)\n-   [Star 4](/login?return_to=%2Fyigitkonur%2Fpineconedb-appscript-integration-for-sheets)\n    \n\nA Google Apps Script custom function to fetch similar categories from a vector database using OpenAI and Pinecone APIs. This function can be used directly in Google Sheets.\n\n[4 stars](/yigitkonur/pineconedb-appscript-integration-for-sheets/stargazers) [0 forks](/yigitkonur/pineconedb-appscript-integration-for-sheets/forks) [Branches](/yigitkonur/pineconedb-appscript-integration-for-sheets/branches) [Tags](/yigitkonur/pineconedb-appscript-integration-for-sheets/tags) [Activity](/yigitkonur/pineconedb-appscript-integration-for-sheets/activity)\n\n[Star](/login?return_to=%2Fyigitkonur%2Fpineconedb-appscript-integration-for-sheets)\n\n[Notifications](/login?return_to=%2Fyigitkonur%2Fpineconedb-appscript-integration-for-sheets) You must be signed in to change notification settings\n\n# yigitkonur/pineconedb-appscript-integration-for-sheets\n\n  \n\nÂ main\n\n[Branches](/yigitkonur/pineconedb-appscript-integration-for-sheets/branches)[Tags](/yigitkonur/pineconedb-appscript-integration-for-sheets/tags)\n\n[](/yigitkonur/pineconedb-appscript-integration-for-sheets/branches)[](/yigitkonur/pineconedb-appscript-integration-for-sheets/tags)\n\nGo to file\n\nCode\n\nOpen more actions menu\n\n## Folders and files\n\nName\n\nName\n\nLast commit message\n\nLast commit date\n\n## Latest commit\n\n## History\n\n[4 Commits](/yigitkonur/pineconedb-appscript-integration-for-sheets/commits/main/)\n\n[](/yigitkonur/pineconedb-appscript-integration-for-sheets/commits/main/)\n\n[README.md](/yigitkonur/pineconedb-appscript-integration-for-sheets/blob/main/README.md \"README.md\")\n\n[README.md](/yigitkonur/pineconedb-appscript-integration-for-sheets/blob/main/README.md \"README.md\")\n\n[script.gs](/yigitkonur/pineconedb-appscript-integration-for-sheets/blob/main/script.gs \"script.gs\")\n\n[script.gs](/yigitkonur/pineconedb-appscript-integration-for-sheets/blob/main/script.gs \"script.gs\")\n\nView all files\n\n## Repository files navigation\n\n# Google Sheets VectorDB Integration\n\n[](#google-sheets-vectordb-integration)\n\n## Description\n\n[](#description)\n\nThis Google Sheets custom function enables you to fetch categories similar to a given keyword from a vector database. It employs the OpenAI API to generate a vector for the keyword and the Pinecone API to locate the most similar categories in the database.\n\nAs the AI department at Wope, we needed something like this to test the embeddings we've created ðŸ‘‡\n\n[![CleanShot 2023-10-04 at 17 27 17@2x](https://private-user-images.githubusercontent.com/9989650/272645083-29814a8d-0a62-4edc-970b-944ee1cc7fc3.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjQ0NTQ3ODgsIm5iZiI6MTc2NDQ1NDQ4OCwicGF0aCI6Ii85OTg5NjUwLzI3MjY0NTA4My0yOTgxNGE4ZC0wYTYyLTRlZGMtOTcwYi05NDRlZTFjYzdmYzMucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTEyOSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTExMjlUMjIxNDQ4WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MzcwYzYyZTVhYTRhMGI2OGVkODUwODg3ZjkzNTZhYzEyNWVjYThjZDM5MmZiMzIyZmUzMzllNDkzZWI1OGU4ZiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.dHrBLvPS_nwSBTOXDgcjcDU3c0dRkpPONesrU3X1CSI)](https://private-user-images.githubusercontent.com/9989650/272645083-29814a8d-0a62-4edc-970b-944ee1cc7fc3.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjQ0NTQ3ODgsIm5iZiI6MTc2NDQ1NDQ4OCwicGF0aCI6Ii85OTg5NjUwLzI3MjY0NTA4My0yOTgxNGE4ZC0wYTYyLTRlZGMtOTcwYi05NDRlZTFjYzdmYzMucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTEyOSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTExMjlUMjIxNDQ4WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MzcwYzYyZTVhYTRhMGI2OGVkODUwODg3ZjkzNTZhYzEyNWVjYThjZDM5MmZiMzIyZmUzMzllNDkzZWI1OGU4ZiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.dHrBLvPS_nwSBTOXDgcjcDU3c0dRkpPONesrU3X1CSI)\n\n## Prerequisites\n\n[](#prerequisites)\n\nTo use this function, you will need:\n\n-   A Google account to access Google Sheets.\n-   An OpenAI account to generate vectors for the keywords.\n-   A Pinecone account to find similar categories in the vector database.\n-   API keys for both OpenAI and Pinecone.\n\n## Configuration\n\n[](#configuration)\n\n1.  Open your Google Sheets document.\n2.  Click on `Extensions > Apps Script`.\n3.  Delete any code in the script editor and replace it with the code from the `VectorDB.gs` file in this repository.\n4.  Replace `'Your-OpenAI-API-Key'` and `'Your-Pinecone-API-Key'` with your actual OpenAI and Pinecone API keys.\n5.  Click on `File > Save`. You can name the project as you like, for example, \"VectorDB Integration\".\n6.  Close the Apps Script Editor.\n\n## Usage\n\n[](#usage)\n\nYou can use the `VECTORDB` function just like any other function in Google Sheets.\n\nHere are the parameters you can use:\n\n-   `keyword` (required): The keyword to find similar categories for. This will be a cell reference or a text string.\n-   `categories` (optional): An array of specific categories to return. Can include any categories present in your metadata. If not provided, the function will return all categories.\n-   `numResults` (optional): The number of results to return. Default is 1.\n-   `showScores` (optional): Whether to display the scores. Default is 0 (don't display scores). Set to 1 to display scores.\n-   `lastN` (optional): The number of last parts of the category path to display. If not provided, displays the full path. For example, if the category path is \"Level1 -> Level2 -> Level3\", setting `lastN` to 1 will display \"Level3\", setting `lastN` to 2 will display \"Level2 -> Level3\".\n-   `separator` (optional): The separator used in the category path. Default is ' -> '.\n\nHere are some examples of how to use the function:\n\n[![CleanShot 2023-10-04 at 17 28 48@2x](https://private-user-images.githubusercontent.com/9989650/272645528-9d0ff58f-24c6-4abf-a4c6-5dc56415ca81.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjQ0NTQ3ODgsIm5iZiI6MTc2NDQ1NDQ4OCwicGF0aCI6Ii85OTg5NjUwLzI3MjY0NTUyOC05ZDBmZjU4Zi0yNGM2LTRhYmYtYTRjNi01ZGM1NjQxNWNhODEucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTEyOSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTExMjlUMjIxNDQ4WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MmY1ZmY4ZTFkMzliMzdjNTRiYTIxZGM5MWQwYTZmMWQ2YzQxNTE0ZTE5NDI3NTQ0OTBkNTA3YjNjNTc3MzM5YiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.-Gkd3xUDd9acUaaZFq_GfpFtEsI_knbBTZ112VV_z_Y)](https://private-user-images.githubusercontent.com/9989650/272645528-9d0ff58f-24c6-4abf-a4c6-5dc56415ca81.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjQ0NTQ3ODgsIm5iZiI6MTc2NDQ1NDQ4OCwicGF0aCI6Ii85OTg5NjUwLzI3MjY0NTUyOC05ZDBmZjU4Zi0yNGM2LTRhYmYtYTRjNi01ZGM1NjQxNWNhODEucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTEyOSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTExMjlUMjIxNDQ4WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MmY1ZmY4ZTFkMzliMzdjNTRiYTIxZGM5MWQwYTZmMWQ2YzQxNTE0ZTE5NDI3NTQ0OTBkNTA3YjNjNTc3MzM5YiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.-Gkd3xUDd9acUaaZFq_GfpFtEsI_knbBTZ112VV_z_Y)\n\n-   `=VECTORDB(A2)`: Returns one result with all categories, without scores. Here, `A2` is the cell reference that contains the keyword.\n-   `=VECTORDB(\"keyword\")`: Returns one result with all categories, without scores. Here, `\"keyword\"` is the keyword string.\n-   `=VECTORDB(A2, {\"Category1\"})`: Returns one result with only `Category1`, without scores.\n-   `=VECTORDB(A2, {\"Category1\", \"Category2\"}, 3)`: Returns three results with `Category1` and `Category2`, without scores.\n-   `=VECTORDB(A2, {\"Category1\"}, 1, 1)`: Returns one result with `Category1`, with scores.\n-   `=VECTORDB(A2, {\"Category1\"}, 3, 1, 2)`: Returns three results with `Category1`, with scores, displaying the last two parts of the category path.\n\nWhen the function returns multiple results, each result will be in a separate row by default. If you want each result in a separate column instead, you can use the `TRANSPOSE()` function:\n\n-   `=TRANSPOSE(VECTORDB(A2))`: Returns one result with all categories, without scores, in a separate column.\n-   `=TRANSPOSE(VECTORDB(A2, {\"Category1\", \"Category2\"}, 3))`: Returns three results with `Category1` and `Category2`, without scores, each in a separate column.\n\n[![CleanShot 2023-10-04 at 17 15 20](https://private-user-images.githubusercontent.com/9989650/272642182-69094370-3b22-45f1-b89a-0e80f124967d.gif?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjQ0NTQ3ODgsIm5iZiI6MTc2NDQ1NDQ4OCwicGF0aCI6Ii85OTg5NjUwLzI3MjY0MjE4Mi02OTA5NDM3MC0zYjIyLTQ1ZjEtYjg5YS0wZTgwZjEyNDk2N2QuZ2lmP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTEyOSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTExMjlUMjIxNDQ4WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9OGU5ZmI4Y2UwOGE2YTZjYjQxMjgxMmY2MjQyZTEyNGZmNTA0ZTk4OWU4NDJmYTMwNzAxMjVmMTUyYmQ3MDA2MiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.oyTej37Bk9jOv8d2F9NrZK3Pd-jC7X4RHnt1FQRZkOs)](https://private-user-images.githubusercontent.com/9989650/272642182-69094370-3b22-45f1-b89a-0e80f124967d.gif?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjQ0NTQ3ODgsIm5iZiI6MTc2NDQ1NDQ4OCwicGF0aCI6Ii85OTg5NjUwLzI3MjY0MjE4Mi02OTA5NDM3MC0zYjIyLTQ1ZjEtYjg5YS0wZTgwZjEyNDk2N2QuZ2lmP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTEyOSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTExMjlUMjIxNDQ4WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9OGU5ZmI4Y2UwOGE2YTZjYjQxMjgxMmY2MjQyZTEyNGZmNTA0ZTk4OWU4NDJmYTMwNzAxMjVmMTUyYmQ3MDA2MiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.oyTej37Bk9jOv8d2F9NrZK3Pd-jC7X4RHnt1FQRZkOs)\n\n## Support\n\n[](#support)\n\nIf you encounter any issues or have any questions about this function, please open an issue in this GitHub repository.\n\n## License\n\n[](#license)\n\nThis project is licensed under the MIT License. See the [LICENSE](/yigitkonur/pineconedb-appscript-integration-for-sheets/blob/main/LICENSE) file for details.\n\n## About\n\nA Google Apps Script custom function to fetch similar categories from a vector database using OpenAI and Pinecone APIs. This function can be used directly in Google Sheets.\n\n### Resources\n\n[Readme](#readme-ov-file)\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n[Activity](/yigitkonur/pineconedb-appscript-integration-for-sheets/activity)\n\n### Stars\n\n[**4** stars](/yigitkonur/pineconedb-appscript-integration-for-sheets/stargazers)\n\n### Watchers\n\n[**1** watching](/yigitkonur/pineconedb-appscript-integration-for-sheets/watchers)\n\n### Forks\n\n[**0** forks](/yigitkonur/pineconedb-appscript-integration-for-sheets/forks)\n\n[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Fpineconedb-appscript-integration-for-sheets&report=yigitkonur+%28user%29)\n\n## [Releases](/yigitkonur/pineconedb-appscript-integration-for-sheets/releases)\n\nNo releases published\n\n## [Packages 0](/users/yigitkonur/packages?repo_name=pineconedb-appscript-integration-for-sheets)\n\nNo packages published  \n\n## Languages\n\n-   [JavaScript 100.0%](/yigitkonur/pineconedb-appscript-integration-for-sheets/search?l=javascript)\n\nYou canâ€™t perform that action at this time.\n\n---\n\n## https://github.com/yigitkonur/context-aware-srt-translation-gpt\n\nGitHub - yigitkonur/context-aware-srt-translation-gpt: A repository trying to translate subtitles with GPT 3.5 Turbo without losing context (using the dynamic window context method).                                             \n\n[Skip to content](#start-of-content)   \n\n## Navigation Menu\n\nToggle navigation\n\n[](/)\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Fcontext-aware-srt-translation-gpt)\n\nAppearance settings\n\n  \n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n\n# Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\n Include my email address so I can be contacted\n\nCancel Submit feedback\n\n# Saved searches\n\n## Use saved searches to filter your results more quickly\n\nName  \n\nQuery \n\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\n\nCancel Create saved search\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Fcontext-aware-srt-translation-gpt)\n\n[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=yigitkonur%2Fcontext-aware-srt-translation-gpt)\n\nAppearance settings\n\nResetting focus\n\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\n\n[yigitkonur](/yigitkonur) / **[context-aware-srt-translation-gpt](/yigitkonur/context-aware-srt-translation-gpt)** Public\n\n-   [Notifications](/login?return_to=%2Fyigitkonur%2Fcontext-aware-srt-translation-gpt) You must be signed in to change notification settings\n-   [Fork 2](/login?return_to=%2Fyigitkonur%2Fcontext-aware-srt-translation-gpt)\n-   [Star 31](/login?return_to=%2Fyigitkonur%2Fcontext-aware-srt-translation-gpt)\n    \n\nA repository trying to translate subtitles with GPT 3.5 Turbo without losing context (using the dynamic window context method).\n\n[31 stars](/yigitkonur/context-aware-srt-translation-gpt/stargazers) [2 forks](/yigitkonur/context-aware-srt-translation-gpt/forks) [Branches](/yigitkonur/context-aware-srt-translation-gpt/branches) [Tags](/yigitkonur/context-aware-srt-translation-gpt/tags) [Activity](/yigitkonur/context-aware-srt-translation-gpt/activity)\n\n[Star](/login?return_to=%2Fyigitkonur%2Fcontext-aware-srt-translation-gpt)\n\n[Notifications](/login?return_to=%2Fyigitkonur%2Fcontext-aware-srt-translation-gpt) You must be signed in to change notification settings\n\n# yigitkonur/context-aware-srt-translation-gpt\n\n  \n\nÂ main\n\n[Branches](/yigitkonur/context-aware-srt-translation-gpt/branches)[Tags](/yigitkonur/context-aware-srt-translation-gpt/tags)\n\n[](/yigitkonur/context-aware-srt-translation-gpt/branches)[](/yigitkonur/context-aware-srt-translation-gpt/tags)\n\nGo to file\n\nCode\n\nOpen more actions menu\n\n## Folders and files\n\nName\n\nName\n\nLast commit message\n\nLast commit date\n\n## Latest commit\n\n## History\n\n[5 Commits](/yigitkonur/context-aware-srt-translation-gpt/commits/main/)\n\n[](/yigitkonur/context-aware-srt-translation-gpt/commits/main/)\n\n[src](/yigitkonur/context-aware-srt-translation-gpt/tree/main/src \"src\")\n\n[src](/yigitkonur/context-aware-srt-translation-gpt/tree/main/src \"src\")\n\n[tests](/yigitkonur/context-aware-srt-translation-gpt/tree/main/tests \"tests\")\n\n[tests](/yigitkonur/context-aware-srt-translation-gpt/tree/main/tests \"tests\")\n\n[.env.example](/yigitkonur/context-aware-srt-translation-gpt/blob/main/.env.example \".env.example\")\n\n[.env.example](/yigitkonur/context-aware-srt-translation-gpt/blob/main/.env.example \".env.example\")\n\n[.gitignore](/yigitkonur/context-aware-srt-translation-gpt/blob/main/.gitignore \".gitignore\")\n\n[.gitignore](/yigitkonur/context-aware-srt-translation-gpt/blob/main/.gitignore \".gitignore\")\n\n[README.md](/yigitkonur/context-aware-srt-translation-gpt/blob/main/README.md \"README.md\")\n\n[README.md](/yigitkonur/context-aware-srt-translation-gpt/blob/main/README.md \"README.md\")\n\n[requirements.txt](/yigitkonur/context-aware-srt-translation-gpt/blob/main/requirements.txt \"requirements.txt\")\n\n[requirements.txt](/yigitkonur/context-aware-srt-translation-gpt/blob/main/requirements.txt \"requirements.txt\")\n\n[run.py](/yigitkonur/context-aware-srt-translation-gpt/blob/main/run.py \"run.py\")\n\n[run.py](/yigitkonur/context-aware-srt-translation-gpt/blob/main/run.py \"run.py\")\n\nView all files\n\n## Repository files navigation\n\n# ðŸŽ¬ context-aware-srt-translation ðŸŽ¬\n\n[](#-context-aware-srt-translation-)\n\n### Stop translating subtitles line by line. Start shipping natural translations.\n\n[](#stop-translating-subtitles-line-by-line-start-shipping-natural-translations)\n\n**_The smarter subtitle translator. It reads your SRT, groups sequential lines for context, and uses GPT to produce translations that actually sound human._**\n\n[![python](https://camo.githubusercontent.com/4808218212ece46251343f2523af0fdfb557a5bef0edc616a82c5480e8cd2da2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e31302b2d3444383745362e7376673f7374796c653d666c61742d737175617265)](#) [![fastapi](https://camo.githubusercontent.com/ee156a544c678f4857fb274b0b51778e314c50fa337186bdd24a90e2c2944220/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f466173744150492d302e3130392b2d3030393638382e7376673f7374796c653d666c61742d737175617265)](#) Â Â â€¢Â Â  [![license](https://camo.githubusercontent.com/b9394454fa0b691582af19a29fc9d773de827bf10e109544bf7b49f16e43032f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d4639413832352e7376673f7374796c653d666c61742d737175617265)](#) [![platform](https://camo.githubusercontent.com/be90eb7ad01a3a68618f2facaf2ae9ab2a0550276a4362e1a5167ad90411858e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d2d6d61634f535f7c5f4c696e75785f7c5f57696e646f77732d3245443537332e7376673f7374796c653d666c61742d737175617265)](#)\n\n[![context window](https://camo.githubusercontent.com/df43c92e4a2c1fe6e247784191ef1a7b9bd407fe6908d866d5adf2c2ff5a0563/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09fa7a05f636f6e746578745f77696e646f772d67726f7570735f335f6c696e65735f61745f6f6e63652d3245443537332e7376673f7374796c653d666f722d7468652d6261646765)](https://camo.githubusercontent.com/df43c92e4a2c1fe6e247784191ef1a7b9bd407fe6908d866d5adf2c2ff5a0563/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09fa7a05f636f6e746578745f77696e646f772d67726f7570735f335f6c696e65735f61745f6f6e63652d3245443537332e7376673f7374796c653d666f722d7468652d6261646765) [![auto fallback](https://camo.githubusercontent.com/6c1866348b314cd12cd769cf0c3f9b19b46e8eabc33eecccd7d483b83cea56f4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09f94845f6175746f5f66616c6c6261636b2d4f70656e41495fe286925f446565704c2d3245443537332e7376673f7374796c653d666f722d7468652d6261646765)](https://camo.githubusercontent.com/6c1866348b314cd12cd769cf0c3f9b19b46e8eabc33eecccd7d483b83cea56f4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09f94845f6175746f5f66616c6c6261636b2d4f70656e41495fe286925f446565704c2d3245443537332e7376673f7374796c653d666f722d7468652d6261646765)\n\n### ðŸ§­ Quick Navigation\n\n[](#-quick-navigation)\n\n[**âš¡ Get Started**](#-get-started-in-60-seconds) â€¢ [**âœ¨ How It Works**](#-how-context-windows-work) â€¢ [**ðŸŽ® API Usage**](#-api-usage) â€¢ [**âš™ï¸ Configuration**](#%EF%B8%8F-configuration) â€¢ [**ðŸ†š Why This Slaps**](#-why-this-slaps-other-methods)\n\n* * *\n\n**context-aware-srt-translation** is the translator your subtitles deserve. Stop feeding GPT one line at a time and getting robotic, disconnected results. This service groups sequential subtitle lines together, giving the AI the context it needs to understand the conversation and produce translations that actually flow naturally.\n\n### ðŸ§ \n\n[](#)\n\n**Context Windows**  \n3 lines translated together\n\n### âš¡\n\n[](#-1)\n\n**Concurrent Processing**  \nParallel chunk translation\n\n### ðŸ”„\n\n[](#-2)\n\n**Auto Fallback**  \nOpenAI â†’ DeepL seamlessly\n\nHow it works:\n\n-   **You:** POST your SRT file to the API\n-   **Service:** Groups lines into context windows, translates concurrently\n-   **Result:** Natural translations that respect conversational flow\n-   **Bonus:** Full statistics on what happened\n\n* * *\n\n## ðŸ’¥ Why This Slaps Other Methods\n\n[](#-why-this-slaps-other-methods)\n\nLine-by-line translation is a vibe-killer. Context windows make other methods look ancient.\n\n**âŒ Line-by-Line (Pain)**\n\n**âœ… Context Windows (Glory)**\n\n\"I think we should...\"  â†’  \"SanÄ±rÄ±m biz...\"\n\"...go there tomorrow\"  â†’  \"...yarÄ±n oraya git\"\n\nDisconnected. Robotic. Wrong verb forms.\n\n\\[\"I think we should...\",\n \"...go there tomorrow\"\\]  â†’  \n\\[\"Bence yarÄ±n oraya...\",\n \"...gitmeliyiz\"\\]\n\nConnected. Natural. Correct grammar.\n\nThe difference is **context**. When GPT sees the full thought, it understands the sentence structure, maintains speaker tone, and produces translations humans would actually write.\n\n* * *\n\n## ðŸš€ Get Started in 60 Seconds\n\n[](#-get-started-in-60-seconds)\n\n### 1\\. Clone & Install\n\n[](#1-clone--install)\n\ngit clone https://github.com/yigitkonur/context-aware-srt-translation-gpt.git\ncd context-aware-srt-translation-gpt\npython3 -m venv .venv && source .venv/bin/activate\npip install -r requirements.txt\n\n### 2\\. Configure\n\n[](#2-configure)\n\ncp .env.example .env\n# Add your OpenAI API key (required)\n# Add DeepL API key (optional fallback)\n\n### 3\\. Run\n\n[](#3-run)\n\npython run.py\n\nThe API is now live at `http://localhost:8000` ðŸŽ‰\n\n* * *\n\n## ðŸ§  How Context Windows Work\n\n[](#-how-context-windows-work)\n\nInstead of translating each subtitle line individually (which loses context), this service groups sequential lines:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Traditional: Line 1 â†’ Translate â†’ Output 1    â”‚\nâ”‚               Line 2 â†’ Translate â†’ Output 2    â”‚\nâ”‚               Line 3 â†’ Translate â†’ Output 3    â”‚\nâ”‚               âŒ No context between lines       â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Context Window:                                â”‚\nâ”‚  [Line 1, Line 2, Line 3] â†’ Translate Together  â”‚\nâ”‚               â†“                                 â”‚\nâ”‚  [Output 1, Output 2, Output 3]                 â”‚\nâ”‚               âœ… AI sees the full picture       â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\nThis allows GPT to:\n\n-   **Maintain speaker continuity** â€” Same character, same voice\n-   **Preserve conversation flow** â€” Questions match answers\n-   **Handle split sentences** â€” \"I think...\" + \"...we should go\" = coherent thought\n-   **Respect cultural context** â€” Idioms translated appropriately\n\n* * *\n\n## ðŸŽ® API Usage\n\n[](#-api-usage)\n\n### Translate Subtitles\n\n[](#translate-subtitles)\n\ncurl -X POST \"http://localhost:8000/subtitle-translate\" \\\\\n  -H \"Content-Type: application/json\" \\\\\n  -d '{\n    \"srt\\_content\": \"1\\\\n00:00:01,000 --> 00:00:04,000\\\\nHello, how are you?\\\\n\\\\n2\\\\n00:00:05,000 --> 00:00:08,000\\\\nI am doing great, thanks!\",\n    \"source\\_language\": \"en\",\n    \"target\\_language\": \"tr\"\n  }'\n\n### Response\n\n[](#response)\n\n{\n  \"translated\\_srt\\_content\": \"1\\\\n00:00:01,000 --> 00:00:04,000\\\\nMerhaba, nasÄ±lsÄ±n?\\\\n\\\\n2\\\\n00:00:05,000 --> 00:00:08,000\\\\nÃ‡ok iyiyim, teÅŸekkÃ¼rler!\",\n  \"status\": \"success\",\n  \"error\\_message\": null,\n  \"stats\": {\n    \"total\\_sentences\": 2,\n    \"translated\\_sentences\": 2,\n    \"failed\\_sentences\": 0,\n    \"success\\_rate\": 100.0,\n    \"openai\\_calls\": 1,\n    \"deepl\\_calls\": 0,\n    \"elapsed\\_seconds\": 1.23\n  }\n}\n\n### Health Check\n\n[](#health-check)\n\ncurl http://localhost:8000/health\n# {\"status\": \"healthy\", \"version\": \"2.0.0\"}\n\n* * *\n\n## âš™ï¸ Configuration\n\n[](#ï¸-configuration)\n\nAll settings via environment variables:\n\nVariable\n\nDefault\n\nDescription\n\n`OPENAI_API_KEY`\n\nâ€”\n\n**Required.** Your OpenAI API key\n\n`DEEPL_API_KEY`\n\nâ€”\n\nOptional fallback service\n\n`OPENAI_MODEL`\n\n`gpt-4o-mini`\n\nModel for translations\n\n`OPENAI_TEMPERATURE`\n\n`0.3`\n\nLower = more consistent\n\n`CONTEXT_WINDOW_SIZE`\n\n`3`\n\nLines per translation chunk\n\n`MAX_CONCURRENT_REQUESTS`\n\n`10`\n\nParallel API calls\n\n`LOG_LEVEL`\n\n`INFO`\n\nLogging verbosity\n\n* * *\n\n## ðŸ“ Project Structure\n\n[](#-project-structure)\n\n```\nsrc/\nâ”œâ”€â”€ config.py              # Environment configuration\nâ”œâ”€â”€ models.py              # Pydantic request/response models\nâ”œâ”€â”€ srt_parser.py          # SRT parsing & reconstruction\nâ”œâ”€â”€ translator.py          # Main orchestration logic\nâ”œâ”€â”€ main.py                # FastAPI application\nâ””â”€â”€ services/\n    â”œâ”€â”€ base.py            # Service interface\n    â”œâ”€â”€ openai_service.py  # OpenAI implementation\n    â””â”€â”€ deepl_service.py   # DeepL fallback\n```\n\n* * *\n\n## ðŸ”¥ API Documentation\n\n[](#-api-documentation)\n\nInteractive docs available when running:\n\n-   **Swagger UI:** `http://localhost:8000/docs`\n-   **ReDoc:** `http://localhost:8000/redoc`\n\n* * *\n\n## ðŸ› ï¸ Development\n\n[](#ï¸-development)\n\n# Setup\npython3 -m venv .venv && source .venv/bin/activate\npip install -r requirements.txt\n\n# Run tests\npytest tests/ -v\n\n# Run with hot reload\npython run.py\n\n* * *\n\n## ðŸ”¥ Common Issues\n\n[](#-common-issues)\n\nProblem\n\nSolution\n\n**OpenAI rate limit**\n\nReduce `MAX_CONCURRENT_REQUESTS`\n\n**DeepL not working**\n\nCheck `DEEPL_API_KEY` is set correctly\n\n**Translations cut off**\n\nIncrease `OPENAI_MAX_TOKENS`\n\n**Wrong language codes**\n\nUse ISO 639-1 codes: `en`, `tr`, `de`, `fr`, etc.\n\n* * *\n\n**Built with ðŸ”¥ because line-by-line subtitle translation is a crime against cinema.**\n\nMIT Â© [YiÄŸit Konur](https://github.com/yigitkonur)\n\n## About\n\nA repository trying to translate subtitles with GPT 3.5 Turbo without losing context (using the dynamic window context method).\n\n### Resources\n\n[Readme](#readme-ov-file)\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n[Activity](/yigitkonur/context-aware-srt-translation-gpt/activity)\n\n### Stars\n\n[**31** stars](/yigitkonur/context-aware-srt-translation-gpt/stargazers)\n\n### Watchers\n\n[**6** watching](/yigitkonur/context-aware-srt-translation-gpt/watchers)\n\n### Forks\n\n[**2** forks](/yigitkonur/context-aware-srt-translation-gpt/forks)\n\n[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Fcontext-aware-srt-translation-gpt&report=yigitkonur+%28user%29)\n\n## [Releases](/yigitkonur/context-aware-srt-translation-gpt/releases)\n\nNo releases published\n\n## [Packages 0](/users/yigitkonur/packages?repo_name=context-aware-srt-translation-gpt)\n\nNo packages published  \n\n## Languages\n\n-   [Python 100.0%](/yigitkonur/context-aware-srt-translation-gpt/search?l=python)\n\nYou canâ€™t perform that action at this time.\n\n---\n\n## https://github.com/yigitkonur/write-into-menubar\n\nGitHub - yigitkonur/write-into-menubar: Write whatever you want into OSX menubar by using BitBar + Alfred Powerpack.                                             \n\n[Skip to content](#start-of-content)   \n\n## Navigation Menu\n\nToggle navigation\n\n[](/)\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Fwrite-into-menubar)\n\nAppearance settings\n\n  \n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n\n# Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\n Include my email address so I can be contacted\n\nCancel Submit feedback\n\n# Saved searches\n\n## Use saved searches to filter your results more quickly\n\nName  \n\nQuery \n\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\n\nCancel Create saved search\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Fwrite-into-menubar)\n\n[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=yigitkonur%2Fwrite-into-menubar)\n\nAppearance settings\n\nResetting focus\n\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\n\n[yigitkonur](/yigitkonur) / **[write-into-menubar](/yigitkonur/write-into-menubar)** Public\n\n-   [Notifications](/login?return_to=%2Fyigitkonur%2Fwrite-into-menubar) You must be signed in to change notification settings\n-   [Fork 3](/login?return_to=%2Fyigitkonur%2Fwrite-into-menubar)\n-   [Star 34](/login?return_to=%2Fyigitkonur%2Fwrite-into-menubar)\n    \n\nWrite whatever you want into OSX menubar by using BitBar + Alfred Powerpack.\n\n[34 stars](/yigitkonur/write-into-menubar/stargazers) [3 forks](/yigitkonur/write-into-menubar/forks) [Branches](/yigitkonur/write-into-menubar/branches) [Tags](/yigitkonur/write-into-menubar/tags) [Activity](/yigitkonur/write-into-menubar/activity)\n\n[Star](/login?return_to=%2Fyigitkonur%2Fwrite-into-menubar)\n\n[Notifications](/login?return_to=%2Fyigitkonur%2Fwrite-into-menubar) You must be signed in to change notification settings\n\n# yigitkonur/write-into-menubar\n\n  \n\nÂ master\n\n[Branches](/yigitkonur/write-into-menubar/branches)[Tags](/yigitkonur/write-into-menubar/tags)\n\n[](/yigitkonur/write-into-menubar/branches)[](/yigitkonur/write-into-menubar/tags)\n\nGo to file\n\nCode\n\nOpen more actions menu\n\n## Folders and files\n\nName\n\nName\n\nLast commit message\n\nLast commit date\n\n## Latest commit\n\n## History\n\n[6 Commits](/yigitkonur/write-into-menubar/commits/master/)\n\n[](/yigitkonur/write-into-menubar/commits/master/)\n\n[readme.md](/yigitkonur/write-into-menubar/blob/master/readme.md \"readme.md\")\n\n[readme.md](/yigitkonur/write-into-menubar/blob/master/readme.md \"readme.md\")\n\n[write-into-menubar-alfred-workflow.alfredworkflow](/yigitkonur/write-into-menubar/blob/master/write-into-menubar-alfred-workflow.alfredworkflow \"write-into-menubar-alfred-workflow.alfredworkflow\")\n\n[write-into-menubar-alfred-workflow.alfredworkflow](/yigitkonur/write-into-menubar/blob/master/write-into-menubar-alfred-workflow.alfredworkflow \"write-into-menubar-alfred-workflow.alfredworkflow\")\n\n[write-into-menubar-bitbar-plugin.1s.sh](/yigitkonur/write-into-menubar/blob/master/write-into-menubar-bitbar-plugin.1s.sh \"write-into-menubar-bitbar-plugin.1s.sh\")\n\n[write-into-menubar-bitbar-plugin.1s.sh](/yigitkonur/write-into-menubar/blob/master/write-into-menubar-bitbar-plugin.1s.sh \"write-into-menubar-bitbar-plugin.1s.sh\")\n\nView all files\n\n## Repository files navigation\n\n# Write Text into Menubar (BitBar + Alfred)\n\n[](#write-text-into-menubar-bitbar--alfred)\n\nDo you deal with tens of different tasks in a hour and end up with forgetting what you do 10 seconds ago? No prob!\n\n[![How To Use](https://camo.githubusercontent.com/0daf523ada9e1547ed52f72a61c80ffc54b477f8e891d7ee11fe421ec5dc5c51/68747470733a2f2f636c6475702e636f6d2f633145536348754d6a652e676966 \"With Animated GIFs\")](https://camo.githubusercontent.com/0daf523ada9e1547ed52f72a61c80ffc54b477f8e891d7ee11fe421ec5dc5c51/68747470733a2f2f636c6475702e636f6d2f633145536348754d6a652e676966)\n\nYou can write a text string to remember which will stick into your menubar - so that you can remember what you were going to do. Just install BitBar + Alfred Powerpack and start to use.\n\n### Installation\n\n[](#installation)\n\n-   Make sure that you have a BitBar extension.\n-   You BitBar plugin folder have to be installed ~/Documents/Bitbar-Plugins/\n-   Drag and drop your BitBar plugin into ~/Documents/Bitbar-Plugins/write-into-menubar-bitbar-plugin.1s.sh\n-   You need to run this Terminal Command to add chmod into your Bitbar Plugin\n\nchmod +x ~/Documents/Bitbar-Plugins/write-into-menubar-bitbar-plugin.1s.sh\n\n### Customization\n\n[](#customization)\n\nYou can also config this plugin according to you needs - just change variables in BitBar plugin:\n\n-   You can change text color by changing: quote\\_color=\"black\"\n-   You can set length of string by changing: max\\_chars=\"30\"\n\n### Dependencies\n\n[](#dependencies)\n\nYou need to have BitBar (completely free) and Alfred Powerpack (paid one) to use this plugin.\n\nTake a look to download then:\n\n-   [Alfred 3](https://www.alfredapp.com/) to run .AlfredWorkflow\n-   [BitBar](https://getbitbar.com/) to show final result of .sh plugin\n\nThis plugin is made by [YiÄŸit Konur](https://github.com/yigitkonur) for my daily routine at [Zeo](https://zeo.org). If you need to get a support - please open an issue.\n\n_Special thanks for [Jan GroÃŸ](https://getbitbar.com/contributors/JanGross) to inspire me by his \"Daily Quote\" plugin to create my own._\n\n## About\n\nWrite whatever you want into OSX menubar by using BitBar + Alfred Powerpack.\n\n### Topics\n\n[alfred](/topics/alfred \"Topic: alfred\") [workflow](/topics/workflow \"Topic: workflow\") [bitbar](/topics/bitbar \"Topic: bitbar\")\n\n### Resources\n\n[Readme](#readme-ov-file)\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n[Activity](/yigitkonur/write-into-menubar/activity)\n\n### Stars\n\n[**34** stars](/yigitkonur/write-into-menubar/stargazers)\n\n### Watchers\n\n[**3** watching](/yigitkonur/write-into-menubar/watchers)\n\n### Forks\n\n[**3** forks](/yigitkonur/write-into-menubar/forks)\n\n[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fyigitkonur%2Fwrite-into-menubar&report=yigitkonur+%28user%29)\n\n## [Releases](/yigitkonur/write-into-menubar/releases)\n\nNo releases published\n\n## [Packages 0](/users/yigitkonur/packages?repo_name=write-into-menubar)\n\nNo packages published  \n\n## Languages\n\n-   [Shell 100.0%](/yigitkonur/write-into-menubar/search?l=shell)\n\nYou canâ€™t perform that action at this time."
    }
  ]
}
